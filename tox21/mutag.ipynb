{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome back! You know the drill:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deepchem in ./env/lib/python3.10/site-packages (2.7.1)\n",
      "Requirement already satisfied: joblib in ./env/lib/python3.10/site-packages (from deepchem) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.21 in ./env/lib/python3.10/site-packages (from deepchem) (1.24.4)\n",
      "Requirement already satisfied: pandas in ./env/lib/python3.10/site-packages (from deepchem) (2.1.3)\n",
      "Requirement already satisfied: scikit-learn in ./env/lib/python3.10/site-packages (from deepchem) (1.3.2)\n",
      "Requirement already satisfied: scipy<1.9 in ./env/lib/python3.10/site-packages (from deepchem) (1.8.1)\n",
      "Requirement already satisfied: rdkit in ./env/lib/python3.10/site-packages (from deepchem) (2023.9.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./env/lib/python3.10/site-packages (from pandas->deepchem) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./env/lib/python3.10/site-packages (from pandas->deepchem) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./env/lib/python3.10/site-packages (from pandas->deepchem) (2023.3)\n",
      "Requirement already satisfied: Pillow in ./env/lib/python3.10/site-packages (from rdkit->deepchem) (10.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./env/lib/python3.10/site-packages (from scikit-learn->deepchem) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in ./env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->deepchem) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: deepchem[torch] in ./env/lib/python3.10/site-packages (2.7.1)\n",
      "Requirement already satisfied: joblib in ./env/lib/python3.10/site-packages (from deepchem[torch]) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.21 in ./env/lib/python3.10/site-packages (from deepchem[torch]) (1.24.4)\n",
      "Requirement already satisfied: pandas in ./env/lib/python3.10/site-packages (from deepchem[torch]) (2.1.3)\n",
      "Requirement already satisfied: scikit-learn in ./env/lib/python3.10/site-packages (from deepchem[torch]) (1.3.2)\n",
      "Requirement already satisfied: scipy<1.9 in ./env/lib/python3.10/site-packages (from deepchem[torch]) (1.8.1)\n",
      "Requirement already satisfied: rdkit in ./env/lib/python3.10/site-packages (from deepchem[torch]) (2023.9.1)\n",
      "Requirement already satisfied: torch in ./env/lib/python3.10/site-packages (from deepchem[torch]) (2.1.0)\n",
      "Requirement already satisfied: torchvision in ./env/lib/python3.10/site-packages (from deepchem[torch]) (0.16.0)\n",
      "Requirement already satisfied: pytorch-lightning in ./env/lib/python3.10/site-packages (from deepchem[torch]) (2.1.1)\n",
      "Requirement already satisfied: dgl in ./env/lib/python3.10/site-packages (from deepchem[torch]) (1.1.2.post1)\n",
      "Requirement already satisfied: dgllife in ./env/lib/python3.10/site-packages (from deepchem[torch]) (0.3.2)\n",
      "Requirement already satisfied: networkx>=2.1 in ./env/lib/python3.10/site-packages (from dgl->deepchem[torch]) (3.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./env/lib/python3.10/site-packages (from dgl->deepchem[torch]) (2.31.0)\n",
      "Requirement already satisfied: tqdm in ./env/lib/python3.10/site-packages (from dgl->deepchem[torch]) (4.66.1)\n",
      "Requirement already satisfied: psutil>=5.8.0 in ./env/lib/python3.10/site-packages (from dgl->deepchem[torch]) (5.9.6)\n",
      "Requirement already satisfied: hyperopt in ./env/lib/python3.10/site-packages (from dgllife->deepchem[torch]) (0.2.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./env/lib/python3.10/site-packages (from scikit-learn->deepchem[torch]) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./env/lib/python3.10/site-packages (from pandas->deepchem[torch]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./env/lib/python3.10/site-packages (from pandas->deepchem[torch]) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./env/lib/python3.10/site-packages (from pandas->deepchem[torch]) (2023.3)\n",
      "Requirement already satisfied: PyYAML>=5.4 in ./env/lib/python3.10/site-packages (from pytorch-lightning->deepchem[torch]) (6.0.1)\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in ./env/lib/python3.10/site-packages (from pytorch-lightning->deepchem[torch]) (2023.10.0)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in ./env/lib/python3.10/site-packages (from pytorch-lightning->deepchem[torch]) (1.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./env/lib/python3.10/site-packages (from pytorch-lightning->deepchem[torch]) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in ./env/lib/python3.10/site-packages (from pytorch-lightning->deepchem[torch]) (4.8.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in ./env/lib/python3.10/site-packages (from pytorch-lightning->deepchem[torch]) (0.9.0)\n",
      "Requirement already satisfied: filelock in ./env/lib/python3.10/site-packages (from torch->deepchem[torch]) (3.13.1)\n",
      "Requirement already satisfied: sympy in ./env/lib/python3.10/site-packages (from torch->deepchem[torch]) (1.12)\n",
      "Requirement already satisfied: jinja2 in ./env/lib/python3.10/site-packages (from torch->deepchem[torch]) (3.1.2)\n",
      "Requirement already satisfied: Pillow in ./env/lib/python3.10/site-packages (from rdkit->deepchem[torch]) (10.1.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./env/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning->deepchem[torch]) (3.9.0rc0)\n",
      "Requirement already satisfied: six>=1.5 in ./env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->deepchem[torch]) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.10/site-packages (from requests>=2.19.0->dgl->deepchem[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.10/site-packages (from requests>=2.19.0->dgl->deepchem[torch]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.10/site-packages (from requests>=2.19.0->dgl->deepchem[torch]) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.10/site-packages (from requests>=2.19.0->dgl->deepchem[torch]) (2023.7.22)\n",
      "Requirement already satisfied: future in ./env/lib/python3.10/site-packages (from hyperopt->dgllife->deepchem[torch]) (0.18.3)\n",
      "Requirement already satisfied: cloudpickle in ./env/lib/python3.10/site-packages (from hyperopt->dgllife->deepchem[torch]) (3.0.0)\n",
      "Requirement already satisfied: py4j in ./env/lib/python3.10/site-packages (from hyperopt->dgllife->deepchem[torch]) (0.10.9.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./env/lib/python3.10/site-packages (from jinja2->torch->deepchem[torch]) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./env/lib/python3.10/site-packages (from sympy->torch->deepchem[torch]) (1.3.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->deepchem[torch]) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->deepchem[torch]) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->deepchem[torch]) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->deepchem[torch]) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->deepchem[torch]) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->deepchem[torch]) (4.0.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: rdkit in ./env/lib/python3.10/site-packages (2023.9.1)\n",
      "Requirement already satisfied: numpy in ./env/lib/python3.10/site-packages (from rdkit) (1.24.4)\n",
      "Requirement already satisfied: Pillow in ./env/lib/python3.10/site-packages (from rdkit) (10.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: torch_geometric in ./env/lib/python3.10/site-packages (2.4.0)\n",
      "Requirement already satisfied: tqdm in ./env/lib/python3.10/site-packages (from torch_geometric) (4.66.1)\n",
      "Requirement already satisfied: numpy in ./env/lib/python3.10/site-packages (from torch_geometric) (1.24.4)\n",
      "Requirement already satisfied: scipy in ./env/lib/python3.10/site-packages (from torch_geometric) (1.8.1)\n",
      "Requirement already satisfied: jinja2 in ./env/lib/python3.10/site-packages (from torch_geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in ./env/lib/python3.10/site-packages (from torch_geometric) (2.31.0)\n",
      "Requirement already satisfied: pyparsing in ./env/lib/python3.10/site-packages (from torch_geometric) (3.1.1)\n",
      "Requirement already satisfied: scikit-learn in ./env/lib/python3.10/site-packages (from torch_geometric) (1.3.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in ./env/lib/python3.10/site-packages (from torch_geometric) (5.9.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./env/lib/python3.10/site-packages (from jinja2->torch_geometric) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.10/site-packages (from requests->torch_geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.10/site-packages (from requests->torch_geometric) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.10/site-packages (from requests->torch_geometric) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.10/site-packages (from requests->torch_geometric) (2023.7.22)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./env/lib/python3.10/site-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./env/lib/python3.10/site-packages (from scikit-learn->torch_geometric) (3.2.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: torch in ./env/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: filelock in ./env/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in ./env/lib/python3.10/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in ./env/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in ./env/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./env/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in ./env/lib/python3.10/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./env/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./env/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pytorch-ignite in ./env/lib/python3.10/site-packages (0.4.13)\n",
      "Requirement already satisfied: torch<3,>=1.3 in ./env/lib/python3.10/site-packages (from pytorch-ignite) (2.1.0)\n",
      "Requirement already satisfied: packaging in ./env/lib/python3.10/site-packages (from pytorch-ignite) (23.2)\n",
      "Requirement already satisfied: filelock in ./env/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in ./env/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (4.8.0)\n",
      "Requirement already satisfied: sympy in ./env/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (1.12)\n",
      "Requirement already satisfied: networkx in ./env/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./env/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (3.1.2)\n",
      "Requirement already satisfied: fsspec in ./env/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./env/lib/python3.10/site-packages (from jinja2->torch<3,>=1.3->pytorch-ignite) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./env/lib/python3.10/site-packages (from sympy->torch<3,>=1.3->pytorch-ignite) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install deepchem\n",
    "!pip install 'deepchem[torch]'\n",
    "!pip install rdkit\n",
    "!pip install torch_geometric\n",
    "!pip install torch\n",
    "!pip install pytorch-ignite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[MUTAG](https://chrsmrrs.github.io/datasets/docs/datasets/#:~:text=MUTAG,MUTAG) is a very popular datset for graph classification on [PapersWithCode](https://paperswithcode.com/task/graph-classification/latest). Experts know best, so let's stand on the shoulders of giants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "dataset = TUDataset(root=\"./data/\", name=\"MUTAG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: MUTAG(188):\n",
      "====================\n",
      "Number of graphs: 188\n",
      "Number of features: 7\n",
      "Number of classes: 2\n",
      "\n",
      "Data(edge_index=[2, 38], x=[17, 7], edge_attr=[38, 4], y=[1])\n",
      "=============================================================\n",
      "Number of nodes: 17\n",
      "Number of edges: 38\n",
      "Average node degree: 2.24\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print('=============================================================')\n",
    "\n",
    "# Gather some statistics about the first graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0s: 63\n",
      "Number of 1s:  125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihirarya/Dev/bcil/tox21/env/lib/python3.10/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "/Users/mihirarya/Dev/bcil/tox21/env/lib/python3.10/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of 0s:\", list(dataset.data.y).count(0))\n",
    "print(\"Number of 1s: \", list(dataset.data.y).count(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/thanos.jpg\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 150 | Test: 38\n"
     ]
    }
   ],
   "source": [
    "dataset.shuffle()\n",
    "split = int(len(dataset) * 0.8)\n",
    "train_dataset, test_dataset = dataset[:split], dataset[split:]\n",
    "print(\"Train:\", len(train_dataset), \"| Test:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(edge_index=[2, 1188], x=[538, 7], edge_attr=[1188, 4], y=[32], batch=[538], ptr=[33])\n",
      "\n",
      "Step 2:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(edge_index=[2, 1266], x=[575, 7], edge_attr=[1266, 4], y=[32], batch=[575], ptr=[33])\n",
      "\n",
      "Step 3:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(edge_index=[2, 1372], x=[619, 7], edge_attr=[1372, 4], y=[32], batch=[619], ptr=[33])\n",
      "\n",
      "Step 4:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(edge_index=[2, 1196], x=[544, 7], edge_attr=[1196, 4], y=[32], batch=[544], ptr=[33])\n",
      "\n",
      "Step 5:\n",
      "=======\n",
      "Number of graphs in the current batch: 22\n",
      "DataBatch(edge_index=[2, 908], x=[408, 7], edge_attr=[908, 4], y=[22], batch=[408], ptr=[23])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "for step, data in enumerate(train_loader):\n",
    "    print(f'Step {step + 1}:')\n",
    "    print('=======')\n",
    "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "    print(data)\n",
    "    print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN(\n",
      "  (conv1): GraphConv(7, 64)\n",
      "  (conv2): GraphConv(64, 64)\n",
      "  (conv3): GraphConv(64, 64)\n",
      "  (lin): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import GraphConv\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GNN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GraphConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2 = GraphConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GraphConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, 1) # Output a binary value (0 or 1) because this is a binary classification problem \n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        x = x.to(self.lin.weight.dtype)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = GNN(hidden_channels=64)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal\n",
    "    acc = (correct / len(y_pred)) * 100 \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import *\n",
    "from ignite.handlers import *\n",
    "from ignite.metrics import *\n",
    "from ignite.utils import *\n",
    "from ignite.contrib.metrics.regression import *\n",
    "from ignite.contrib.metrics import *\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "def train(loader):\n",
    "    model.train()\n",
    "\n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    for data in loader:  # Iterate in batches over the training dataset.\n",
    "        try: \n",
    "            # 1. Forward pass (model outputs raw logits)\n",
    "            y_logits = model(data.x, data.edge_index, data.batch)\n",
    "            y_pred = torch.round(torch.sigmoid(y_logits))\n",
    "            y_true = data.y # extract target column\n",
    "\n",
    "            # 2. Calculate loss/accuracy\n",
    "            loss = loss_fn(y_logits.squeeze(), y_true.float())\n",
    "            train_loss += loss\n",
    "            train_acc += accuracy_fn(y_true=y_true, y_pred=y_pred.squeeze())\n",
    "\n",
    "            # 3. Optimizer zero grad\n",
    "            optimizer.zero_grad() \n",
    "\n",
    "            # 4. Loss backwards\n",
    "            loss.backward()  \n",
    "\n",
    "            # 5. Optimizer step\n",
    "            optimizer.step()\n",
    "        except:\n",
    "            continue\n",
    "    train_loss /= len(loader)\n",
    "    train_acc /= len(loader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "def test(loader):\n",
    "     model.eval()\n",
    "\n",
    "     test_loss, test_acc = 0, 0\n",
    "     def eval_step(engine, batch):\n",
    "        return batch\n",
    "\n",
    "     default_evaluator = Engine(eval_step)\n",
    " \n",
    "     roc_auc = ROC_AUC()\n",
    "     roc_auc.attach(default_evaluator, 'roc_auc')\n",
    "     roc_auc = 0\n",
    "     for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "         y_logits = model(data.x, data.edge_index, data.batch)\n",
    "         y_pred = torch.round(torch.sigmoid(y_logits))\n",
    "         y_true = data.y # extract target column\n",
    "\n",
    "         test_loss += loss_fn(y_logits.squeeze(), y_true.float())\n",
    "         test_acc += accuracy_fn(y_true=y_true, y_pred=y_pred.squeeze())\n",
    "         state = default_evaluator.run([[y_pred.squeeze(), y_true]])\n",
    "         roc_auc += state.metrics['roc_auc']\n",
    "     test_loss /= len(loader)\n",
    "     test_acc /= len(loader)\n",
    "     roc_auc /= len(loader)\n",
    "     print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}% | ROC-AUC: {roc_auc:.2f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.81634 | Train accuracy: 47.56%\n",
      "Test loss: 0.66830 | Test accuracy: 60.94% | ROC-AUC: 0.50 \n",
      "\n",
      "Train loss: 0.63178 | Train accuracy: 65.23%\n",
      "Test loss: 0.65238 | Test accuracy: 60.94% | ROC-AUC: 0.50 \n",
      "\n",
      "Train loss: 0.59958 | Train accuracy: 65.85%\n",
      "Test loss: 0.63826 | Test accuracy: 60.94% | ROC-AUC: 0.50 \n",
      "\n",
      "Train loss: 0.58764 | Train accuracy: 66.14%\n",
      "Test loss: 0.60446 | Test accuracy: 60.94% | ROC-AUC: 0.50 \n",
      "\n",
      "Train loss: 0.58866 | Train accuracy: 64.72%\n",
      "Test loss: 0.57928 | Test accuracy: 60.94% | ROC-AUC: 0.50 \n",
      "\n",
      "Train loss: 0.52276 | Train accuracy: 65.85%\n",
      "Test loss: 0.51399 | Test accuracy: 60.94% | ROC-AUC: 0.50 \n",
      "\n",
      "Train loss: 0.49319 | Train accuracy: 75.80%\n",
      "Test loss: 0.42835 | Test accuracy: 79.17% | ROC-AUC: 0.81 \n",
      "\n",
      "Train loss: 0.46928 | Train accuracy: 78.52%\n",
      "Test loss: 0.54696 | Test accuracy: 72.40% | ROC-AUC: 0.71 \n",
      "\n",
      "Train loss: 0.53056 | Train accuracy: 74.83%\n",
      "Test loss: 0.41366 | Test accuracy: 85.94% | ROC-AUC: 0.90 \n",
      "\n",
      "Train loss: 0.47523 | Train accuracy: 77.33%\n",
      "Test loss: 0.41977 | Test accuracy: 69.27% | ROC-AUC: 0.68 \n",
      "\n",
      "Train loss: 0.44429 | Train accuracy: 78.01%\n",
      "Test loss: 0.42101 | Test accuracy: 87.50% | ROC-AUC: 0.91 \n",
      "\n",
      "Train loss: 0.43910 | Train accuracy: 77.05%\n",
      "Test loss: 0.36527 | Test accuracy: 79.17% | ROC-AUC: 0.81 \n",
      "\n",
      "Train loss: 0.44245 | Train accuracy: 78.92%\n",
      "Test loss: 0.34686 | Test accuracy: 87.50% | ROC-AUC: 0.91 \n",
      "\n",
      "Train loss: 0.42198 | Train accuracy: 77.39%\n",
      "Test loss: 0.34527 | Test accuracy: 87.50% | ROC-AUC: 0.90 \n",
      "\n",
      "Train loss: 0.39528 | Train accuracy: 80.74%\n",
      "Test loss: 0.34282 | Test accuracy: 87.50% | ROC-AUC: 0.90 \n",
      "\n",
      "Train loss: 0.37850 | Train accuracy: 80.80%\n",
      "Test loss: 0.34096 | Test accuracy: 89.06% | ROC-AUC: 0.92 \n",
      "\n",
      "Train loss: 0.37842 | Train accuracy: 80.68%\n",
      "Test loss: 0.33204 | Test accuracy: 89.06% | ROC-AUC: 0.92 \n",
      "\n",
      "Train loss: 0.36152 | Train accuracy: 80.40%\n",
      "Test loss: 0.33533 | Test accuracy: 89.06% | ROC-AUC: 0.92 \n",
      "\n",
      "Train loss: 0.37191 | Train accuracy: 82.27%\n",
      "Test loss: 0.41574 | Test accuracy: 79.17% | ROC-AUC: 0.80 \n",
      "\n",
      "Train loss: 0.38350 | Train accuracy: 80.68%\n",
      "Test loss: 0.40120 | Test accuracy: 84.38% | ROC-AUC: 0.89 \n",
      "\n",
      "Train loss: 0.39238 | Train accuracy: 82.33%\n",
      "Test loss: 0.40004 | Test accuracy: 79.17% | ROC-AUC: 0.80 \n",
      "\n",
      "Train loss: 0.34310 | Train accuracy: 83.47%\n",
      "Test loss: 0.36074 | Test accuracy: 82.81% | ROC-AUC: 0.86 \n",
      "\n",
      "Train loss: 0.33359 | Train accuracy: 82.90%\n",
      "Test loss: 0.36421 | Test accuracy: 80.73% | ROC-AUC: 0.82 \n",
      "\n",
      "Train loss: 0.34411 | Train accuracy: 80.51%\n",
      "Test loss: 0.39195 | Test accuracy: 79.17% | ROC-AUC: 0.80 \n",
      "\n",
      "Train loss: 0.30568 | Train accuracy: 80.68%\n",
      "Test loss: 0.37901 | Test accuracy: 80.73% | ROC-AUC: 0.82 \n",
      "\n",
      "Train loss: 0.31190 | Train accuracy: 84.09%\n",
      "Test loss: 0.37188 | Test accuracy: 80.73% | ROC-AUC: 0.82 \n",
      "\n",
      "Train loss: 0.28321 | Train accuracy: 86.93%\n",
      "Test loss: 0.39687 | Test accuracy: 80.73% | ROC-AUC: 0.82 \n",
      "\n",
      "Train loss: 0.34875 | Train accuracy: 80.74%\n",
      "Test loss: 0.52516 | Test accuracy: 67.71% | ROC-AUC: 0.64 \n",
      "\n",
      "Train loss: 0.32867 | Train accuracy: 81.31%\n",
      "Test loss: 0.39124 | Test accuracy: 80.73% | ROC-AUC: 0.82 \n",
      "\n",
      "Train loss: 0.28473 | Train accuracy: 87.56%\n",
      "Test loss: 0.40201 | Test accuracy: 80.73% | ROC-AUC: 0.82 \n",
      "\n",
      "Train loss: 0.27587 | Train accuracy: 87.27%\n",
      "Test loss: 0.46460 | Test accuracy: 80.73% | ROC-AUC: 0.81 \n",
      "\n",
      "Train loss: 0.30833 | Train accuracy: 83.92%\n",
      "Test loss: 0.45857 | Test accuracy: 80.73% | ROC-AUC: 0.81 \n",
      "\n",
      "Train loss: 0.38356 | Train accuracy: 81.59%\n",
      "Test loss: 0.45230 | Test accuracy: 84.38% | ROC-AUC: 0.87 \n",
      "\n",
      "Train loss: 0.40705 | Train accuracy: 81.65%\n",
      "Test loss: 0.50624 | Test accuracy: 69.27% | ROC-AUC: 0.65 \n",
      "\n",
      "Train loss: 0.36511 | Train accuracy: 80.17%\n",
      "Test loss: 0.44152 | Test accuracy: 79.17% | ROC-AUC: 0.78 \n",
      "\n",
      "Train loss: 0.32583 | Train accuracy: 86.65%\n",
      "Test loss: 0.44773 | Test accuracy: 89.06% | ROC-AUC: 0.91 \n",
      "\n",
      "Train loss: 0.30834 | Train accuracy: 84.20%\n",
      "Test loss: 0.45644 | Test accuracy: 79.17% | ROC-AUC: 0.78 \n",
      "\n",
      "Train loss: 0.28808 | Train accuracy: 86.93%\n",
      "Test loss: 0.42352 | Test accuracy: 80.73% | ROC-AUC: 0.82 \n",
      "\n",
      "Train loss: 0.27939 | Train accuracy: 88.24%\n",
      "Test loss: 0.45877 | Test accuracy: 80.73% | ROC-AUC: 0.79 \n",
      "\n",
      "Train loss: 0.24636 | Train accuracy: 89.43%\n",
      "Test loss: 0.43951 | Test accuracy: 83.85% | ROC-AUC: 0.85 \n",
      "\n",
      "Train loss: 0.24718 | Train accuracy: 86.65%\n",
      "Test loss: 0.47101 | Test accuracy: 83.85% | ROC-AUC: 0.85 \n",
      "\n",
      "Train loss: 0.23307 | Train accuracy: 91.93%\n",
      "Test loss: 0.51739 | Test accuracy: 83.85% | ROC-AUC: 0.85 \n",
      "\n",
      "Train loss: 0.24090 | Train accuracy: 91.31%\n",
      "Test loss: 0.51352 | Test accuracy: 83.85% | ROC-AUC: 0.85 \n",
      "\n",
      "Train loss: 0.24477 | Train accuracy: 88.81%\n",
      "Test loss: 0.47299 | Test accuracy: 82.29% | ROC-AUC: 0.83 \n",
      "\n",
      "Train loss: 0.23715 | Train accuracy: 92.84%\n",
      "Test loss: 0.49869 | Test accuracy: 83.85% | ROC-AUC: 0.85 \n",
      "\n",
      "Train loss: 0.20456 | Train accuracy: 90.62%\n",
      "Test loss: 0.49387 | Test accuracy: 83.85% | ROC-AUC: 0.85 \n",
      "\n",
      "Train loss: 0.21604 | Train accuracy: 92.56%\n",
      "Test loss: 0.51693 | Test accuracy: 83.85% | ROC-AUC: 0.85 \n",
      "\n",
      "Train loss: 0.19312 | Train accuracy: 91.25%\n",
      "Test loss: 0.54995 | Test accuracy: 83.85% | ROC-AUC: 0.85 \n",
      "\n",
      "Train loss: 0.20936 | Train accuracy: 92.50%\n",
      "Test loss: 0.60992 | Test accuracy: 82.29% | ROC-AUC: 0.82 \n",
      "\n",
      "Train loss: 0.20959 | Train accuracy: 90.06%\n",
      "Test loss: 0.51569 | Test accuracy: 83.85% | ROC-AUC: 0.85 \n",
      "\n",
      "Train loss: 0.22290 | Train accuracy: 90.68%\n",
      "Test loss: 0.53816 | Test accuracy: 83.85% | ROC-AUC: 0.85 \n",
      "\n",
      "Train loss: 0.20298 | Train accuracy: 91.93%\n",
      "Test loss: 0.58660 | Test accuracy: 73.96% | ROC-AUC: 0.73 \n",
      "\n",
      "Train loss: 0.21558 | Train accuracy: 87.27%\n",
      "Test loss: 0.53095 | Test accuracy: 83.85% | ROC-AUC: 0.85 \n",
      "\n",
      "Train loss: 0.19166 | Train accuracy: 92.50%\n",
      "Test loss: 0.59652 | Test accuracy: 83.85% | ROC-AUC: 0.85 \n",
      "\n",
      "Train loss: 0.22507 | Train accuracy: 91.02%\n",
      "Test loss: 0.53934 | Test accuracy: 83.85% | ROC-AUC: 0.85 \n",
      "\n",
      "Train loss: 0.20600 | Train accuracy: 89.38%\n",
      "Test loss: 0.50832 | Test accuracy: 83.85% | ROC-AUC: 0.85 \n",
      "\n",
      "Train loss: 0.23760 | Train accuracy: 91.65%\n",
      "Test loss: 0.53511 | Test accuracy: 83.85% | ROC-AUC: 0.85 \n",
      "\n",
      "Train loss: 0.17926 | Train accuracy: 91.25%\n",
      "Test loss: 0.67898 | Test accuracy: 72.40% | ROC-AUC: 0.71 \n",
      "\n",
      "Train loss: 0.22298 | Train accuracy: 90.34%\n",
      "Test loss: 0.72490 | Test accuracy: 70.83% | ROC-AUC: 0.68 \n",
      "\n",
      "Train loss: 0.31841 | Train accuracy: 86.70%\n",
      "Test loss: 0.48695 | Test accuracy: 80.73% | ROC-AUC: 0.82 \n",
      "\n",
      "Train loss: 0.22601 | Train accuracy: 88.52%\n",
      "Test loss: 0.57707 | Test accuracy: 72.40% | ROC-AUC: 0.71 \n",
      "\n",
      "Train loss: 0.21971 | Train accuracy: 91.02%\n",
      "Test loss: 0.45962 | Test accuracy: 83.85% | ROC-AUC: 0.85 \n",
      "\n",
      "Train loss: 0.20165 | Train accuracy: 91.59%\n",
      "Test loss: 0.55129 | Test accuracy: 82.29% | ROC-AUC: 0.82 \n",
      "\n",
      "Train loss: 0.19232 | Train accuracy: 89.38%\n",
      "Test loss: 0.49877 | Test accuracy: 83.85% | ROC-AUC: 0.85 \n",
      "\n",
      "Train loss: 0.19738 | Train accuracy: 93.52%\n",
      "Test loss: 0.54694 | Test accuracy: 83.85% | ROC-AUC: 0.85 \n",
      "\n",
      "Train loss: 0.17074 | Train accuracy: 92.22%\n",
      "Test loss: 0.57290 | Test accuracy: 83.85% | ROC-AUC: 0.85 \n",
      "\n",
      "Train loss: 0.19116 | Train accuracy: 92.56%\n",
      "Test loss: 0.59444 | Test accuracy: 75.52% | ROC-AUC: 0.76 \n",
      "\n",
      "Train loss: 0.17583 | Train accuracy: 94.38%\n",
      "Test loss: 0.57068 | Test accuracy: 72.40% | ROC-AUC: 0.71 \n",
      "\n",
      "Train loss: 0.17803 | Train accuracy: 92.84%\n",
      "Test loss: 0.58267 | Test accuracy: 73.96% | ROC-AUC: 0.73 \n",
      "\n",
      "Train loss: 0.17362 | Train accuracy: 91.59%\n",
      "Test loss: 0.57672 | Test accuracy: 83.85% | ROC-AUC: 0.85 \n",
      "\n",
      "Train loss: 0.17001 | Train accuracy: 94.09%\n",
      "Test loss: 0.63511 | Test accuracy: 72.40% | ROC-AUC: 0.71 \n",
      "\n",
      "Train loss: 0.16562 | Train accuracy: 93.47%\n",
      "Test loss: 0.60570 | Test accuracy: 73.96% | ROC-AUC: 0.73 \n",
      "\n",
      "Train loss: 0.16808 | Train accuracy: 92.84%\n",
      "Test loss: 0.57926 | Test accuracy: 73.96% | ROC-AUC: 0.73 \n",
      "\n",
      "Train loss: 0.20212 | Train accuracy: 93.18%\n",
      "Test loss: 0.59738 | Test accuracy: 82.29% | ROC-AUC: 0.82 \n",
      "\n",
      "Train loss: 0.16371 | Train accuracy: 93.18%\n",
      "Test loss: 0.60978 | Test accuracy: 72.40% | ROC-AUC: 0.71 \n",
      "\n",
      "Train loss: 0.15696 | Train accuracy: 92.84%\n",
      "Test loss: 0.57160 | Test accuracy: 82.29% | ROC-AUC: 0.82 \n",
      "\n",
      "Train loss: 0.16394 | Train accuracy: 92.56%\n",
      "Test loss: 0.65447 | Test accuracy: 72.40% | ROC-AUC: 0.71 \n",
      "\n",
      "Train loss: 0.16804 | Train accuracy: 92.50%\n",
      "Test loss: 0.61360 | Test accuracy: 83.85% | ROC-AUC: 0.85 \n",
      "\n",
      "Train loss: 0.17589 | Train accuracy: 91.59%\n",
      "Test loss: 0.78713 | Test accuracy: 72.40% | ROC-AUC: 0.71 \n",
      "\n",
      "Train loss: 0.15906 | Train accuracy: 93.75%\n",
      "Test loss: 0.56595 | Test accuracy: 83.85% | ROC-AUC: 0.85 \n",
      "\n",
      "Train loss: 0.16391 | Train accuracy: 95.34%\n",
      "Test loss: 0.79199 | Test accuracy: 70.83% | ROC-AUC: 0.68 \n",
      "\n",
      "Train loss: 0.19874 | Train accuracy: 91.31%\n",
      "Test loss: 0.57811 | Test accuracy: 83.85% | ROC-AUC: 0.85 \n",
      "\n",
      "Train loss: 0.22981 | Train accuracy: 90.11%\n",
      "Test loss: 0.79560 | Test accuracy: 70.83% | ROC-AUC: 0.68 \n",
      "\n",
      "Train loss: 0.23801 | Train accuracy: 92.22%\n",
      "Test loss: 0.60977 | Test accuracy: 83.85% | ROC-AUC: 0.85 \n",
      "\n",
      "Train loss: 0.25297 | Train accuracy: 86.02%\n",
      "Test loss: 0.51100 | Test accuracy: 83.85% | ROC-AUC: 0.85 \n",
      "\n",
      "Train loss: 0.21061 | Train accuracy: 92.50%\n",
      "Test loss: 0.51684 | Test accuracy: 73.96% | ROC-AUC: 0.73 \n",
      "\n",
      "Train loss: 0.18801 | Train accuracy: 92.22%\n",
      "Test loss: 0.54412 | Test accuracy: 83.85% | ROC-AUC: 0.85 \n",
      "\n",
      "Train loss: 0.17005 | Train accuracy: 90.40%\n",
      "Test loss: 0.58567 | Test accuracy: 83.85% | ROC-AUC: 0.85 \n",
      "\n",
      "Train loss: 0.18951 | Train accuracy: 91.02%\n",
      "Test loss: 0.58023 | Test accuracy: 82.29% | ROC-AUC: 0.82 \n",
      "\n",
      "Train loss: 0.15861 | Train accuracy: 93.75%\n",
      "Test loss: 0.50712 | Test accuracy: 83.85% | ROC-AUC: 0.85 \n",
      "\n",
      "Train loss: 0.16833 | Train accuracy: 92.56%\n",
      "Test loss: 0.52850 | Test accuracy: 83.85% | ROC-AUC: 0.85 \n",
      "\n",
      "Train loss: 0.15667 | Train accuracy: 93.18%\n",
      "Test loss: 0.48686 | Test accuracy: 83.85% | ROC-AUC: 0.85 \n",
      "\n",
      "Train loss: 0.17667 | Train accuracy: 92.61%\n",
      "Test loss: 0.58933 | Test accuracy: 72.40% | ROC-AUC: 0.71 \n",
      "\n",
      "Train loss: 0.15873 | Train accuracy: 93.12%\n",
      "Test loss: 0.54497 | Test accuracy: 83.85% | ROC-AUC: 0.85 \n",
      "\n",
      "Train loss: 0.15455 | Train accuracy: 93.18%\n",
      "Test loss: 0.59462 | Test accuracy: 82.29% | ROC-AUC: 0.82 \n",
      "\n",
      "Train loss: 0.16436 | Train accuracy: 92.90%\n",
      "Test loss: 0.62880 | Test accuracy: 72.40% | ROC-AUC: 0.71 \n",
      "\n",
      "Train loss: 0.17116 | Train accuracy: 93.81%\n",
      "Test loss: 0.65624 | Test accuracy: 72.40% | ROC-AUC: 0.71 \n",
      "\n",
      "Train loss: 0.16947 | Train accuracy: 90.68%\n",
      "Test loss: 0.61103 | Test accuracy: 72.40% | ROC-AUC: 0.71 \n",
      "\n",
      "Train loss: 0.15337 | Train accuracy: 93.18%\n",
      "Test loss: 0.57626 | Test accuracy: 82.29% | ROC-AUC: 0.82 \n",
      "\n",
      "Train loss: 0.14064 | Train accuracy: 94.09%\n",
      "Test loss: 0.64599 | Test accuracy: 72.40% | ROC-AUC: 0.71 \n",
      "\n",
      "Train loss: 0.14860 | Train accuracy: 92.22%\n",
      "Test loss: 0.65170 | Test accuracy: 72.40% | ROC-AUC: 0.71 \n",
      "\n",
      "Train loss: 0.15030 | Train accuracy: 92.84%\n",
      "Test loss: 0.58172 | Test accuracy: 82.29% | ROC-AUC: 0.82 \n",
      "\n",
      "Train loss: 0.15676 | Train accuracy: 92.90%\n",
      "Test loss: 0.69282 | Test accuracy: 70.83% | ROC-AUC: 0.68 \n",
      "\n",
      "Train loss: 0.13442 | Train accuracy: 95.00%\n",
      "Test loss: 0.57378 | Test accuracy: 83.85% | ROC-AUC: 0.85 \n",
      "\n",
      "Train loss: 0.13240 | Train accuracy: 93.75%\n",
      "Test loss: 0.69295 | Test accuracy: 73.96% | ROC-AUC: 0.72 \n",
      "\n",
      "Train loss: 0.14011 | Train accuracy: 92.84%\n",
      "Test loss: 0.55863 | Test accuracy: 82.29% | ROC-AUC: 0.82 \n",
      "\n",
      "Train loss: 0.16906 | Train accuracy: 93.47%\n",
      "Test loss: 0.66483 | Test accuracy: 72.40% | ROC-AUC: 0.71 \n",
      "\n",
      "Train loss: 0.18342 | Train accuracy: 89.49%\n",
      "Test loss: 0.63419 | Test accuracy: 72.40% | ROC-AUC: 0.71 \n",
      "\n",
      "Train loss: 0.17685 | Train accuracy: 93.18%\n",
      "Test loss: 0.53245 | Test accuracy: 73.96% | ROC-AUC: 0.73 \n",
      "\n",
      "Train loss: 0.15732 | Train accuracy: 90.34%\n",
      "Test loss: 0.54434 | Test accuracy: 72.40% | ROC-AUC: 0.69 \n",
      "\n",
      "Train loss: 0.14306 | Train accuracy: 93.52%\n",
      "Test loss: 0.51301 | Test accuracy: 83.85% | ROC-AUC: 0.85 \n",
      "\n",
      "Train loss: 0.13300 | Train accuracy: 93.81%\n",
      "Test loss: 0.74149 | Test accuracy: 70.83% | ROC-AUC: 0.68 \n",
      "\n",
      "Train loss: 0.14684 | Train accuracy: 94.09%\n",
      "Test loss: 0.70419 | Test accuracy: 72.40% | ROC-AUC: 0.71 \n",
      "\n",
      "Train loss: 0.13382 | Train accuracy: 93.12%\n",
      "Test loss: 0.77082 | Test accuracy: 72.40% | ROC-AUC: 0.71 \n",
      "\n",
      "Train loss: 0.14958 | Train accuracy: 91.99%\n",
      "Test loss: 0.72816 | Test accuracy: 72.40% | ROC-AUC: 0.71 \n",
      "\n",
      "Train loss: 0.15358 | Train accuracy: 92.90%\n",
      "Test loss: 0.75256 | Test accuracy: 72.40% | ROC-AUC: 0.71 \n",
      "\n",
      "Train loss: 0.17661 | Train accuracy: 91.93%\n",
      "Test loss: 0.64082 | Test accuracy: 72.40% | ROC-AUC: 0.69 \n",
      "\n",
      "Train loss: 0.20671 | Train accuracy: 89.49%\n",
      "Test loss: 0.81527 | Test accuracy: 70.83% | ROC-AUC: 0.68 \n",
      "\n",
      "Train loss: 0.18501 | Train accuracy: 90.68%\n",
      "Test loss: 0.51399 | Test accuracy: 82.29% | ROC-AUC: 0.82 \n",
      "\n",
      "Train loss: 0.17896 | Train accuracy: 91.31%\n",
      "Test loss: 0.65268 | Test accuracy: 80.73% | ROC-AUC: 0.79 \n",
      "\n",
      "Train loss: 0.13146 | Train accuracy: 93.47%\n",
      "Test loss: 0.62511 | Test accuracy: 80.73% | ROC-AUC: 0.79 \n",
      "\n",
      "Train loss: 0.13339 | Train accuracy: 93.18%\n",
      "Test loss: 0.67707 | Test accuracy: 70.83% | ROC-AUC: 0.68 \n",
      "\n",
      "Train loss: 0.13220 | Train accuracy: 93.18%\n",
      "Test loss: 0.73365 | Test accuracy: 70.83% | ROC-AUC: 0.68 \n",
      "\n",
      "Train loss: 0.12533 | Train accuracy: 94.09%\n",
      "Test loss: 0.75627 | Test accuracy: 70.83% | ROC-AUC: 0.68 \n",
      "\n",
      "Train loss: 0.11523 | Train accuracy: 95.34%\n",
      "Test loss: 0.74883 | Test accuracy: 70.83% | ROC-AUC: 0.68 \n",
      "\n",
      "Train loss: 0.10544 | Train accuracy: 94.15%\n",
      "Test loss: 0.75938 | Test accuracy: 70.83% | ROC-AUC: 0.68 \n",
      "\n",
      "Train loss: 0.11905 | Train accuracy: 93.52%\n",
      "Test loss: 0.71270 | Test accuracy: 79.17% | ROC-AUC: 0.76 \n",
      "\n",
      "Train loss: 0.12990 | Train accuracy: 93.47%\n",
      "Test loss: 0.88927 | Test accuracy: 72.40% | ROC-AUC: 0.69 \n",
      "\n",
      "Train loss: 0.13192 | Train accuracy: 95.00%\n",
      "Test loss: 0.68550 | Test accuracy: 70.83% | ROC-AUC: 0.68 \n",
      "\n",
      "Train loss: 0.11701 | Train accuracy: 92.84%\n",
      "Test loss: 0.70185 | Test accuracy: 70.83% | ROC-AUC: 0.68 \n",
      "\n",
      "Train loss: 0.13153 | Train accuracy: 93.81%\n",
      "Test loss: 0.77727 | Test accuracy: 72.40% | ROC-AUC: 0.69 \n",
      "\n",
      "Train loss: 0.11913 | Train accuracy: 94.09%\n",
      "Test loss: 0.58787 | Test accuracy: 82.29% | ROC-AUC: 0.82 \n",
      "\n",
      "Train loss: 0.11762 | Train accuracy: 94.43%\n",
      "Test loss: 0.70540 | Test accuracy: 72.40% | ROC-AUC: 0.69 \n",
      "\n",
      "Train loss: 0.12190 | Train accuracy: 92.56%\n",
      "Test loss: 0.61916 | Test accuracy: 80.73% | ROC-AUC: 0.79 \n",
      "\n",
      "Train loss: 0.16497 | Train accuracy: 92.61%\n",
      "Test loss: 0.97302 | Test accuracy: 72.40% | ROC-AUC: 0.69 \n",
      "\n",
      "Train loss: 0.27522 | Train accuracy: 87.90%\n",
      "Test loss: 0.78115 | Test accuracy: 82.29% | ROC-AUC: 0.83 \n",
      "\n",
      "Train loss: 0.34911 | Train accuracy: 84.43%\n",
      "Test loss: 0.64838 | Test accuracy: 75.52% | ROC-AUC: 0.73 \n",
      "\n",
      "Train loss: 0.25379 | Train accuracy: 89.77%\n",
      "Test loss: 0.51956 | Test accuracy: 80.73% | ROC-AUC: 0.79 \n",
      "\n",
      "Train loss: 0.13970 | Train accuracy: 94.72%\n",
      "Test loss: 0.55250 | Test accuracy: 80.73% | ROC-AUC: 0.79 \n",
      "\n",
      "Train loss: 0.15529 | Train accuracy: 91.65%\n",
      "Test loss: 0.69290 | Test accuracy: 70.83% | ROC-AUC: 0.68 \n",
      "\n",
      "Train loss: 0.12676 | Train accuracy: 94.43%\n",
      "Test loss: 0.66415 | Test accuracy: 80.73% | ROC-AUC: 0.79 \n",
      "\n",
      "Train loss: 0.14353 | Train accuracy: 93.18%\n",
      "Test loss: 0.73206 | Test accuracy: 79.17% | ROC-AUC: 0.76 \n",
      "\n",
      "Train loss: 0.16377 | Train accuracy: 90.68%\n",
      "Test loss: 0.65283 | Test accuracy: 79.17% | ROC-AUC: 0.76 \n",
      "\n",
      "Train loss: 0.13558 | Train accuracy: 93.18%\n",
      "Test loss: 0.63147 | Test accuracy: 79.17% | ROC-AUC: 0.76 \n",
      "\n",
      "Train loss: 0.13584 | Train accuracy: 92.22%\n",
      "Test loss: 0.63400 | Test accuracy: 80.73% | ROC-AUC: 0.79 \n",
      "\n",
      "Train loss: 0.13637 | Train accuracy: 94.09%\n",
      "Test loss: 0.51731 | Test accuracy: 80.73% | ROC-AUC: 0.79 \n",
      "\n",
      "Train loss: 0.11453 | Train accuracy: 93.81%\n",
      "Test loss: 0.66090 | Test accuracy: 73.96% | ROC-AUC: 0.70 \n",
      "\n",
      "Train loss: 0.11940 | Train accuracy: 94.09%\n",
      "Test loss: 0.55580 | Test accuracy: 82.29% | ROC-AUC: 0.80 \n",
      "\n",
      "Train loss: 0.13306 | Train accuracy: 93.81%\n",
      "Test loss: 0.54007 | Test accuracy: 82.29% | ROC-AUC: 0.80 \n",
      "\n",
      "Train loss: 0.11856 | Train accuracy: 94.43%\n",
      "Test loss: 0.56807 | Test accuracy: 82.29% | ROC-AUC: 0.80 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 150\n",
    "for epoch in range(epochs):\n",
    "    train(train_loader)\n",
    "    test(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very reasonable results! Call us Leibniz-Newton, the way we integrated these changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
