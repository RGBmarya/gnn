{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Okay. Alright. That's fine.*\n",
    "\n",
    "\\- Drake\n",
    "\n",
    "\n",
    "\n",
    "Hyperparameter optimization did not as expected, but we have more exciting things ahead of us: creating our own graph classifier. Let's approach this task using PyTorch Geometric using this [example](https://colab.research.google.com/drive/1I8a0DfQ3fI7Njc62__mVXUlcAleUclnb?usp=sharing#scrollTo=mHSP6-RBOqCE) as reference.\n",
    "\n",
    "We can break this down into a few steps:\n",
    "- Convert SMILES data into graph data\n",
    "- Mini-batch graph data\n",
    "- Define Graph Neural Network for graph classification\n",
    "- Train model and evaluate - you know the drill \n",
    "\n",
    "Let's get to it ðŸ¤–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deepchem in ./env/lib/python3.10/site-packages (2.7.1)\n",
      "Requirement already satisfied: joblib in ./env/lib/python3.10/site-packages (from deepchem) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.21 in ./env/lib/python3.10/site-packages (from deepchem) (1.24.4)\n",
      "Requirement already satisfied: pandas in ./env/lib/python3.10/site-packages (from deepchem) (2.1.3)\n",
      "Requirement already satisfied: scikit-learn in ./env/lib/python3.10/site-packages (from deepchem) (1.3.2)\n",
      "Requirement already satisfied: scipy<1.9 in ./env/lib/python3.10/site-packages (from deepchem) (1.8.1)\n",
      "Requirement already satisfied: rdkit in ./env/lib/python3.10/site-packages (from deepchem) (2023.9.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./env/lib/python3.10/site-packages (from pandas->deepchem) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./env/lib/python3.10/site-packages (from pandas->deepchem) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./env/lib/python3.10/site-packages (from pandas->deepchem) (2023.3)\n",
      "Requirement already satisfied: Pillow in ./env/lib/python3.10/site-packages (from rdkit->deepchem) (10.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./env/lib/python3.10/site-packages (from scikit-learn->deepchem) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in ./env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->deepchem) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: deepchem[torch] in ./env/lib/python3.10/site-packages (2.7.1)\n",
      "Requirement already satisfied: joblib in ./env/lib/python3.10/site-packages (from deepchem[torch]) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.21 in ./env/lib/python3.10/site-packages (from deepchem[torch]) (1.24.4)\n",
      "Requirement already satisfied: pandas in ./env/lib/python3.10/site-packages (from deepchem[torch]) (2.1.3)\n",
      "Requirement already satisfied: scikit-learn in ./env/lib/python3.10/site-packages (from deepchem[torch]) (1.3.2)\n",
      "Requirement already satisfied: scipy<1.9 in ./env/lib/python3.10/site-packages (from deepchem[torch]) (1.8.1)\n",
      "Requirement already satisfied: rdkit in ./env/lib/python3.10/site-packages (from deepchem[torch]) (2023.9.1)\n",
      "Requirement already satisfied: torch in ./env/lib/python3.10/site-packages (from deepchem[torch]) (2.1.0)\n",
      "Requirement already satisfied: torchvision in ./env/lib/python3.10/site-packages (from deepchem[torch]) (0.16.0)\n",
      "Requirement already satisfied: pytorch-lightning in ./env/lib/python3.10/site-packages (from deepchem[torch]) (2.1.1)\n",
      "Requirement already satisfied: dgl in ./env/lib/python3.10/site-packages (from deepchem[torch]) (1.1.2.post1)\n",
      "Requirement already satisfied: dgllife in ./env/lib/python3.10/site-packages (from deepchem[torch]) (0.3.2)\n",
      "Requirement already satisfied: networkx>=2.1 in ./env/lib/python3.10/site-packages (from dgl->deepchem[torch]) (3.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./env/lib/python3.10/site-packages (from dgl->deepchem[torch]) (2.31.0)\n",
      "Requirement already satisfied: tqdm in ./env/lib/python3.10/site-packages (from dgl->deepchem[torch]) (4.66.1)\n",
      "Requirement already satisfied: psutil>=5.8.0 in ./env/lib/python3.10/site-packages (from dgl->deepchem[torch]) (5.9.6)\n",
      "Requirement already satisfied: hyperopt in ./env/lib/python3.10/site-packages (from dgllife->deepchem[torch]) (0.2.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./env/lib/python3.10/site-packages (from scikit-learn->deepchem[torch]) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./env/lib/python3.10/site-packages (from pandas->deepchem[torch]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./env/lib/python3.10/site-packages (from pandas->deepchem[torch]) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./env/lib/python3.10/site-packages (from pandas->deepchem[torch]) (2023.3)\n",
      "Requirement already satisfied: PyYAML>=5.4 in ./env/lib/python3.10/site-packages (from pytorch-lightning->deepchem[torch]) (6.0.1)\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in ./env/lib/python3.10/site-packages (from pytorch-lightning->deepchem[torch]) (2023.10.0)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in ./env/lib/python3.10/site-packages (from pytorch-lightning->deepchem[torch]) (1.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./env/lib/python3.10/site-packages (from pytorch-lightning->deepchem[torch]) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in ./env/lib/python3.10/site-packages (from pytorch-lightning->deepchem[torch]) (4.8.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in ./env/lib/python3.10/site-packages (from pytorch-lightning->deepchem[torch]) (0.9.0)\n",
      "Requirement already satisfied: filelock in ./env/lib/python3.10/site-packages (from torch->deepchem[torch]) (3.13.1)\n",
      "Requirement already satisfied: sympy in ./env/lib/python3.10/site-packages (from torch->deepchem[torch]) (1.12)\n",
      "Requirement already satisfied: jinja2 in ./env/lib/python3.10/site-packages (from torch->deepchem[torch]) (3.1.2)\n",
      "Requirement already satisfied: Pillow in ./env/lib/python3.10/site-packages (from rdkit->deepchem[torch]) (10.1.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./env/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning->deepchem[torch]) (3.9.0rc0)\n",
      "Requirement already satisfied: six>=1.5 in ./env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->deepchem[torch]) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.10/site-packages (from requests>=2.19.0->dgl->deepchem[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.10/site-packages (from requests>=2.19.0->dgl->deepchem[torch]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.10/site-packages (from requests>=2.19.0->dgl->deepchem[torch]) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.10/site-packages (from requests>=2.19.0->dgl->deepchem[torch]) (2023.7.22)\n",
      "Requirement already satisfied: future in ./env/lib/python3.10/site-packages (from hyperopt->dgllife->deepchem[torch]) (0.18.3)\n",
      "Requirement already satisfied: cloudpickle in ./env/lib/python3.10/site-packages (from hyperopt->dgllife->deepchem[torch]) (3.0.0)\n",
      "Requirement already satisfied: py4j in ./env/lib/python3.10/site-packages (from hyperopt->dgllife->deepchem[torch]) (0.10.9.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./env/lib/python3.10/site-packages (from jinja2->torch->deepchem[torch]) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./env/lib/python3.10/site-packages (from sympy->torch->deepchem[torch]) (1.3.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->deepchem[torch]) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->deepchem[torch]) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->deepchem[torch]) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->deepchem[torch]) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->deepchem[torch]) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->deepchem[torch]) (4.0.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: rdkit in ./env/lib/python3.10/site-packages (2023.9.1)\n",
      "Requirement already satisfied: numpy in ./env/lib/python3.10/site-packages (from rdkit) (1.24.4)\n",
      "Requirement already satisfied: Pillow in ./env/lib/python3.10/site-packages (from rdkit) (10.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: torch_geometric in ./env/lib/python3.10/site-packages (2.4.0)\n",
      "Requirement already satisfied: tqdm in ./env/lib/python3.10/site-packages (from torch_geometric) (4.66.1)\n",
      "Requirement already satisfied: numpy in ./env/lib/python3.10/site-packages (from torch_geometric) (1.24.4)\n",
      "Requirement already satisfied: scipy in ./env/lib/python3.10/site-packages (from torch_geometric) (1.8.1)\n",
      "Requirement already satisfied: jinja2 in ./env/lib/python3.10/site-packages (from torch_geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in ./env/lib/python3.10/site-packages (from torch_geometric) (2.31.0)\n",
      "Requirement already satisfied: pyparsing in ./env/lib/python3.10/site-packages (from torch_geometric) (3.1.1)\n",
      "Requirement already satisfied: scikit-learn in ./env/lib/python3.10/site-packages (from torch_geometric) (1.3.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in ./env/lib/python3.10/site-packages (from torch_geometric) (5.9.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./env/lib/python3.10/site-packages (from jinja2->torch_geometric) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.10/site-packages (from requests->torch_geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.10/site-packages (from requests->torch_geometric) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.10/site-packages (from requests->torch_geometric) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.10/site-packages (from requests->torch_geometric) (2023.7.22)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./env/lib/python3.10/site-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./env/lib/python3.10/site-packages (from scikit-learn->torch_geometric) (3.2.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install deepchem\n",
    "!pip install 'deepchem[torch]'\n",
    "!pip install rdkit\n",
    "!pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01:30:52] WARNING: not removing hydrogen atom without neighbors\n",
      "[01:31:04] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "import deepchem as dc\n",
    "\n",
    "tasks, datasets, transformers = dc.molnet.load_tox21(featurizer='GraphConv', reload=False)\n",
    "train_dataset, valid_dataset, test_dataset = datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a close look at this dataset by inspecting the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DiskDataset X.shape: (6264,), y.shape: (6264, 12), w.shape: (6264, 12), task_names: ['NR-AR' 'NR-AR-LBD' 'NR-AhR' ... 'SR-HSE' 'SR-MMP' 'SR-p53']>\n",
      "[<deepchem.feat.mol_graphs.ConvMol object at 0x2cc648100>\n",
      " <deepchem.feat.mol_graphs.ConvMol object at 0x2c6a7b040>\n",
      " <deepchem.feat.mol_graphs.ConvMol object at 0x2a192dc00> ...\n",
      " <deepchem.feat.mol_graphs.ConvMol object at 0x29a92f6d0>\n",
      " <deepchem.feat.mol_graphs.ConvMol object at 0x29a96c070>\n",
      " <deepchem.feat.mol_graphs.ConvMol object at 0x29a96c760>]\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)\n",
    "print(train_dataset.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there are **6264** graphs (molecules) in our training dataset, where *X* stores the molecules as ConvMol objects, *y* stores the hot-encoded output vector with one entry for each of the **12** measures/tasks, and a weights matrix *w*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's one particular molecule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This molecule has 11 atoms with 75 features each.\n"
     ]
    }
   ],
   "source": [
    "test_mol = train_dataset.X[0]\n",
    "print(f\"This molecule has {test_mol.n_atoms} atoms with {test_mol.n_feat} features each.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6264, 783, 784)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(valid_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note above sizes of our training, validation, and test datasets. However, we can't just operate on the above data directly as molecular information is stored as a [SMILES](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) string (that is, simplified molecular-input line-entry system). Try saying that five times fast. In short, the specification enables structural information of molecules to be encoded into a string.\n",
    "\n",
    "For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CC(O)(P(=O)(O)O)P(=O)(O)O'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.ids[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, open-source is once again our savior: [SciPy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.spmatrix.html) supplies a few helper functions to convert sparse adjacency matrices  into graph data that we *can* use with PyTorch Geometric. From there, we can extract additional metadata to help understand the numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "import numpy as np\n",
    "def adjacency_list_to_sparse(adj_list):\n",
    "    num_nodes = len(adj_list)\n",
    "    rows, cols = [], []\n",
    "\n",
    "    for i, neighbors in enumerate(adj_list):\n",
    "        rows.extend([i] * len(neighbors))\n",
    "        cols.extend(neighbors)\n",
    "\n",
    "    adjacency_matrix = scipy.sparse.coo_matrix((np.ones_like(rows), (rows, cols)),\n",
    "                                              shape=(num_nodes, num_nodes),\n",
    "                                              dtype=np.float32)\n",
    "\n",
    "    return adjacency_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from torch_geometric.utils.convert import from_scipy_sparse_matrix\n",
    "\n",
    "\n",
    "def to_data(mol_graph):\n",
    "\n",
    "    x = mol_graph.get_atom_features()\n",
    "\n",
    "    adj_list = mol_graph.get_adjacency_list()\n",
    "    sparse_mat = adjacency_list_to_sparse(adj_list)\n",
    "    edge_index, edge_attr = from_scipy_sparse_matrix(sparse_mat)\n",
    "    \n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little clarification on the `Data` object might help:\n",
    "\n",
    "1. **x (Node Feature Matrix):**\n",
    "   - This parameter represents the feature matrix for each node in the graph.\n",
    "   - It is a PyTorch tensor with shape [num_nodes, num_node_features].\n",
    "   - Each row corresponds to a node, and each column corresponds to a feature of that node.\n",
    "   - For example, if you are representing atoms in a molecule, `x` could contain features like atomic number, charge, etc.\n",
    "\n",
    "\n",
    "2. **edge_index (Graph Connectivity):**\n",
    "   - `edge_index` represents the graph connectivity in COO (Coordinate List) format.\n",
    "   - It is a PyTorch tensor with shape [2, num_edges].\n",
    "   - Each column of `edge_index` contains the indices of two nodes that form an edge.\n",
    "   - For an undirected graph, (i, j) and (j, i) should both be present in the `edge_index`.\n",
    "\n",
    "\n",
    "3. **edge_attr (Edge Feature Matrix):**\n",
    "   - `edge_attr` represents the feature matrix for each edge in the graph.\n",
    "   - It is a PyTorch tensor with shape [num_edges, num_edge_features].\n",
    "   - Each row corresponds to an edge, and each column corresponds to a feature of that edge.\n",
    "   - This is often used to store information like bond types, distances, or any other edge-specific features.\n",
    "\n",
    "While there are a few other parameters, these three collectively provide a comprehensive representation of the graph needed for our specific use case.\n",
    "\n",
    "Let's convert all our datasets from ConvMol to Data objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_graph = []\n",
    "for mol_graph in train_dataset.X:\n",
    "    data = to_data(mol_graph)\n",
    "    train_dataset_graph.append(data)\n",
    "\n",
    "valid_dataset_graph = []\n",
    "for mol_graph in valid_dataset.X:\n",
    "    data = to_data(mol_graph)\n",
    "    valid_dataset_graph.append(data)\n",
    "\n",
    "test_dataset_graph = []\n",
    "for mol_graph in test_dataset.X:\n",
    "    data = to_data(mol_graph)\n",
    "    test_dataset_graph.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[11, 75], edge_index=[2, 20], edge_attr=[20])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_graph[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "train_loader = DataLoader(train_dataset_graph, batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset_graph, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2204], edge_attr=[2204], batch=[1089], ptr=[65])\n",
      "\n",
      "Step 2:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 1988], edge_attr=[1988], batch=[969], ptr=[65])\n",
      "\n",
      "Step 3:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2202], edge_attr=[2202], batch=[1085], ptr=[65])\n",
      "\n",
      "Step 4:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 1814], edge_attr=[1814], batch=[907], ptr=[65])\n",
      "\n",
      "Step 5:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2130], edge_attr=[2130], batch=[1032], ptr=[65])\n",
      "\n",
      "Step 6:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2046], edge_attr=[2046], batch=[1004], ptr=[65])\n",
      "\n",
      "Step 7:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 1988], edge_attr=[1988], batch=[985], ptr=[65])\n",
      "\n",
      "Step 8:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2150], edge_attr=[2150], batch=[1036], ptr=[65])\n",
      "\n",
      "Step 9:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2204], edge_attr=[2204], batch=[1081], ptr=[65])\n",
      "\n",
      "Step 10:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2140], edge_attr=[2140], batch=[1057], ptr=[65])\n",
      "\n",
      "Step 11:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2116], edge_attr=[2116], batch=[1045], ptr=[65])\n",
      "\n",
      "Step 12:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2330], edge_attr=[2330], batch=[1146], ptr=[65])\n",
      "\n",
      "Step 13:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2126], edge_attr=[2126], batch=[1042], ptr=[65])\n",
      "\n",
      "Step 14:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2612], edge_attr=[2612], batch=[1267], ptr=[65])\n",
      "\n",
      "Step 15:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2046], edge_attr=[2046], batch=[1009], ptr=[65])\n",
      "\n",
      "Step 16:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2310], edge_attr=[2310], batch=[1134], ptr=[65])\n",
      "\n",
      "Step 17:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2562], edge_attr=[2562], batch=[1238], ptr=[65])\n",
      "\n",
      "Step 18:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2474], edge_attr=[2474], batch=[1195], ptr=[65])\n",
      "\n",
      "Step 19:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2174], edge_attr=[2174], batch=[1071], ptr=[65])\n",
      "\n",
      "Step 20:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2102], edge_attr=[2102], batch=[1028], ptr=[65])\n",
      "\n",
      "Step 21:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2030], edge_attr=[2030], batch=[989], ptr=[65])\n",
      "\n",
      "Step 22:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 1856], edge_attr=[1856], batch=[925], ptr=[65])\n",
      "\n",
      "Step 23:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2124], edge_attr=[2124], batch=[1044], ptr=[65])\n",
      "\n",
      "Step 24:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 1888], edge_attr=[1888], batch=[938], ptr=[65])\n",
      "\n",
      "Step 25:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2320], edge_attr=[2320], batch=[1130], ptr=[65])\n",
      "\n",
      "Step 26:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2240], edge_attr=[2240], batch=[1088], ptr=[65])\n",
      "\n",
      "Step 27:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 1984], edge_attr=[1984], batch=[971], ptr=[65])\n",
      "\n",
      "Step 28:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 1848], edge_attr=[1848], batch=[932], ptr=[65])\n",
      "\n",
      "Step 29:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2308], edge_attr=[2308], batch=[1119], ptr=[65])\n",
      "\n",
      "Step 30:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 1966], edge_attr=[1966], batch=[965], ptr=[65])\n",
      "\n",
      "Step 31:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 1974], edge_attr=[1974], batch=[986], ptr=[65])\n",
      "\n",
      "Step 32:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2232], edge_attr=[2232], batch=[1089], ptr=[65])\n",
      "\n",
      "Step 33:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 1970], edge_attr=[1970], batch=[970], ptr=[65])\n",
      "\n",
      "Step 34:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 1930], edge_attr=[1930], batch=[956], ptr=[65])\n",
      "\n",
      "Step 35:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2326], edge_attr=[2326], batch=[1122], ptr=[65])\n",
      "\n",
      "Step 36:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2192], edge_attr=[2192], batch=[1083], ptr=[65])\n",
      "\n",
      "Step 37:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2406], edge_attr=[2406], batch=[1174], ptr=[65])\n",
      "\n",
      "Step 38:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2000], edge_attr=[2000], batch=[987], ptr=[65])\n",
      "\n",
      "Step 39:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 1990], edge_attr=[1990], batch=[983], ptr=[65])\n",
      "\n",
      "Step 40:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2084], edge_attr=[2084], batch=[1024], ptr=[65])\n",
      "\n",
      "Step 41:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2278], edge_attr=[2278], batch=[1105], ptr=[65])\n",
      "\n",
      "Step 42:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2200], edge_attr=[2200], batch=[1070], ptr=[65])\n",
      "\n",
      "Step 43:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2104], edge_attr=[2104], batch=[1035], ptr=[65])\n",
      "\n",
      "Step 44:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2134], edge_attr=[2134], batch=[1040], ptr=[65])\n",
      "\n",
      "Step 45:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2038], edge_attr=[2038], batch=[1008], ptr=[65])\n",
      "\n",
      "Step 46:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 1918], edge_attr=[1918], batch=[960], ptr=[65])\n",
      "\n",
      "Step 47:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2348], edge_attr=[2348], batch=[1147], ptr=[65])\n",
      "\n",
      "Step 48:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2316], edge_attr=[2316], batch=[1128], ptr=[65])\n",
      "\n",
      "Step 49:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2106], edge_attr=[2106], batch=[1040], ptr=[65])\n",
      "\n",
      "Step 50:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2146], edge_attr=[2146], batch=[1050], ptr=[65])\n",
      "\n",
      "Step 51:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2028], edge_attr=[2028], batch=[999], ptr=[65])\n",
      "\n",
      "Step 52:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2254], edge_attr=[2254], batch=[1090], ptr=[65])\n",
      "\n",
      "Step 53:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2086], edge_attr=[2086], batch=[1025], ptr=[65])\n",
      "\n",
      "Step 54:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 1988], edge_attr=[1988], batch=[980], ptr=[65])\n",
      "\n",
      "Step 55:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2078], edge_attr=[2078], batch=[1010], ptr=[65])\n",
      "\n",
      "Step 56:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2144], edge_attr=[2144], batch=[1058], ptr=[65])\n",
      "\n",
      "Step 57:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2454], edge_attr=[2454], batch=[1193], ptr=[65])\n",
      "\n",
      "Step 58:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2398], edge_attr=[2398], batch=[1170], ptr=[65])\n",
      "\n",
      "Step 59:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2360], edge_attr=[2360], batch=[1148], ptr=[65])\n",
      "\n",
      "Step 60:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2180], edge_attr=[2180], batch=[1062], ptr=[65])\n",
      "\n",
      "Step 61:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2268], edge_attr=[2268], batch=[1104], ptr=[65])\n",
      "\n",
      "Step 62:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2214], edge_attr=[2214], batch=[1079], ptr=[65])\n",
      "\n",
      "Step 63:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2254], edge_attr=[2254], batch=[1096], ptr=[65])\n",
      "\n",
      "Step 64:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2156], edge_attr=[2156], batch=[1053], ptr=[65])\n",
      "\n",
      "Step 65:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2066], edge_attr=[2066], batch=[1020], ptr=[65])\n",
      "\n",
      "Step 66:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2160], edge_attr=[2160], batch=[1045], ptr=[65])\n",
      "\n",
      "Step 67:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2022], edge_attr=[2022], batch=[988], ptr=[65])\n",
      "\n",
      "Step 68:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2176], edge_attr=[2176], batch=[1085], ptr=[65])\n",
      "\n",
      "Step 69:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2236], edge_attr=[2236], batch=[1104], ptr=[65])\n",
      "\n",
      "Step 70:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2352], edge_attr=[2352], batch=[1152], ptr=[65])\n",
      "\n",
      "Step 71:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2262], edge_attr=[2262], batch=[1095], ptr=[65])\n",
      "\n",
      "Step 72:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 1968], edge_attr=[1968], batch=[973], ptr=[65])\n",
      "\n",
      "Step 73:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2294], edge_attr=[2294], batch=[1119], ptr=[65])\n",
      "\n",
      "Step 74:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2038], edge_attr=[2038], batch=[1014], ptr=[65])\n",
      "\n",
      "Step 75:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2622], edge_attr=[2622], batch=[1272], ptr=[65])\n",
      "\n",
      "Step 76:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2022], edge_attr=[2022], batch=[997], ptr=[65])\n",
      "\n",
      "Step 77:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2162], edge_attr=[2162], batch=[1052], ptr=[65])\n",
      "\n",
      "Step 78:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2278], edge_attr=[2278], batch=[1127], ptr=[65])\n",
      "\n",
      "Step 79:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2192], edge_attr=[2192], batch=[1073], ptr=[65])\n",
      "\n",
      "Step 80:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2018], edge_attr=[2018], batch=[986], ptr=[65])\n",
      "\n",
      "Step 81:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2204], edge_attr=[2204], batch=[1075], ptr=[65])\n",
      "\n",
      "Step 82:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 1978], edge_attr=[1978], batch=[977], ptr=[65])\n",
      "\n",
      "Step 83:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2152], edge_attr=[2152], batch=[1054], ptr=[65])\n",
      "\n",
      "Step 84:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2032], edge_attr=[2032], batch=[999], ptr=[65])\n",
      "\n",
      "Step 85:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2014], edge_attr=[2014], batch=[999], ptr=[65])\n",
      "\n",
      "Step 86:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2268], edge_attr=[2268], batch=[1119], ptr=[65])\n",
      "\n",
      "Step 87:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2016], edge_attr=[2016], batch=[1002], ptr=[65])\n",
      "\n",
      "Step 88:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 1952], edge_attr=[1952], batch=[958], ptr=[65])\n",
      "\n",
      "Step 89:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2256], edge_attr=[2256], batch=[1100], ptr=[65])\n",
      "\n",
      "Step 90:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2206], edge_attr=[2206], batch=[1078], ptr=[65])\n",
      "\n",
      "Step 91:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2452], edge_attr=[2452], batch=[1196], ptr=[65])\n",
      "\n",
      "Step 92:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2092], edge_attr=[2092], batch=[1036], ptr=[65])\n",
      "\n",
      "Step 93:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2034], edge_attr=[2034], batch=[1004], ptr=[65])\n",
      "\n",
      "Step 94:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2226], edge_attr=[2226], batch=[1081], ptr=[65])\n",
      "\n",
      "Step 95:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2386], edge_attr=[2386], batch=[1166], ptr=[65])\n",
      "\n",
      "Step 96:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2114], edge_attr=[2114], batch=[1030], ptr=[65])\n",
      "\n",
      "Step 97:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2410], edge_attr=[2410], batch=[1188], ptr=[65])\n",
      "\n",
      "Step 98:\n",
      "=======\n",
      "Number of graphs in the current batch: 56\n",
      "DataBatch(x=[56], edge_index=[2, 2054], edge_attr=[2054], batch=[1005], ptr=[57])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step, data in enumerate(train_loader):\n",
    "    print(f'Step {step + 1}:')\n",
    "    print('=======')\n",
    "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "    print(data)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm. Slight issue with the x parameter, but no clear solution is popping out to me at the moment. As my friend Dan likes to say, \"Let's circle back to this.\"\n",
    "\n",
    "Also, small (*very* consequential) update: after spending 2 days trying to get perfectly preprocess this data, I have discovered that PyTorch Geometric supplies its own MoleculeNet class, complete with a Tox 21 dataset ðŸ¥².\n",
    "\n",
    "Despite how much my RAM has suffered due to tabs upon tabs of documentation, I'd say that this process helped clarify **how** and **why** we preprocess our data. Now let's condense yesterday's work into two lines!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: Tox21(7831):\n",
      "====================\n",
      "Number of graphs: 7831\n",
      "Number of features: 9\n",
      "Number of classes: 12\n",
      "\n",
      "Data(x=[16, 9], edge_index=[2, 34], edge_attr=[34, 3], smiles='CCOc1ccc2nc(S(N)(=O)=O)sc2c1', y=[1, 12])\n",
      "=============================================================\n",
      "Number of nodes: 16\n",
      "Number of edges: 34\n",
      "Average node degree: 2.12\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import MoleculeNet\n",
    "dataset = MoleculeNet(root=\"./data/\", name=\"Tox21\")\n",
    "\n",
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print('=============================================================')\n",
    "\n",
    "# Gather some statistics about the first graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 12 labels, meaning 12 different tasks to predict. \n",
    "Predicting the presence of all 12 for every molecule is error-prone as an entry for every task is not present for every molecule (i.e., pesky NaNs!). Take a look:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., nan, nan, 0., 0., 1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this reason, let's tighten our scope: let's predict the presence of NR-AhR (column 3) in a molecule.\n",
    "\n",
    "The first step to to **drop rows with a \"NaN\" value for NR-AhR**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihirarya/Dev/bcil/tox21/env/lib/python3.10/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "/Users/mihirarya/Dev/bcil/tox21/env/lib/python3.10/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "column_index_to_check = 2\n",
    "dataset.data.x = dataset.data.x.to(torch.float32)\n",
    "dataset.data.y = dataset.data.y.long()\n",
    "dataset = dataset.shuffle()\n",
    "filtered_dataset = [data for data in dataset if not torch.isnan(data.y[0][column_index_to_check]).any()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we split our data into training and test datasets (a classic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 6264\n",
      "Number of test graphs: 1567\n"
     ]
    }
   ],
   "source": [
    "split = int(0.8 * len(dataset))\n",
    "\n",
    "train_dataset, test_dataset = filtered_dataset[:split], filtered_dataset[split:]\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its beautiful. We can finally move on..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step: **Mini-batching**.\n",
    "\n",
    "Instead of \"stacking\" equally-sized matrices into a single mini-batch, as we may have done with image data, we take an alternative approach with graph data. \"Why overcomplicate things?\" you may ask. According to PyTorch Geometric [documentation](https://colab.research.google.com/drive/1I8a0DfQ3fI7Njc62__mVXUlcAleUclnb?usp=sharing#scrollTo=0gZ-l0npPIca):\n",
    "\n",
    "1. GNN operators that rely on a **message passing scheme** (more on this later) do not need to be modified since messages are not exchanged between two nodes that belong to different graphs\n",
    "\n",
    "2. There is no computational or memory overhead since adjacency matrices are saved in a sparse fashion holding only non-zero entries (*i.e.*, the edges)\n",
    "\n",
    "PyTorch Geometric automatically takes care of **batching multiple graphs into a single giant graph** with the help of the [`torch_geometric.data.DataLoader`](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.DataLoader) class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1155, 9], edge_index=[2, 2404], edge_attr=[2404, 3], smiles=[64], y=[64, 12], batch=[1155], ptr=[65])\n",
      "\n",
      "Step 2:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1126, 9], edge_index=[2, 2336], edge_attr=[2336, 3], smiles=[64], y=[64, 12], batch=[1126], ptr=[65])\n",
      "\n",
      "Step 3:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1117, 9], edge_index=[2, 2306], edge_attr=[2306, 3], smiles=[64], y=[64, 12], batch=[1117], ptr=[65])\n",
      "\n",
      "Step 4:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1242, 9], edge_index=[2, 2558], edge_attr=[2558, 3], smiles=[64], y=[64, 12], batch=[1242], ptr=[65])\n",
      "\n",
      "Step 5:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1210, 9], edge_index=[2, 2514], edge_attr=[2514, 3], smiles=[64], y=[64, 12], batch=[1210], ptr=[65])\n",
      "\n",
      "Step 6:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1338, 9], edge_index=[2, 2784], edge_attr=[2784, 3], smiles=[64], y=[64, 12], batch=[1338], ptr=[65])\n",
      "\n",
      "Step 7:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1240, 9], edge_index=[2, 2584], edge_attr=[2584, 3], smiles=[64], y=[64, 12], batch=[1240], ptr=[65])\n",
      "\n",
      "Step 8:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1255, 9], edge_index=[2, 2610], edge_attr=[2610, 3], smiles=[64], y=[64, 12], batch=[1255], ptr=[65])\n",
      "\n",
      "Step 9:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1159, 9], edge_index=[2, 2412], edge_attr=[2412, 3], smiles=[64], y=[64, 12], batch=[1159], ptr=[65])\n",
      "\n",
      "Step 10:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1247, 9], edge_index=[2, 2586], edge_attr=[2586, 3], smiles=[64], y=[64, 12], batch=[1247], ptr=[65])\n",
      "\n",
      "Step 11:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1131, 9], edge_index=[2, 2326], edge_attr=[2326, 3], smiles=[64], y=[64, 12], batch=[1131], ptr=[65])\n",
      "\n",
      "Step 12:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1220, 9], edge_index=[2, 2578], edge_attr=[2578, 3], smiles=[64], y=[64, 12], batch=[1220], ptr=[65])\n",
      "\n",
      "Step 13:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1006, 9], edge_index=[2, 2082], edge_attr=[2082, 3], smiles=[64], y=[64, 12], batch=[1006], ptr=[65])\n",
      "\n",
      "Step 14:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1220, 9], edge_index=[2, 2538], edge_attr=[2538, 3], smiles=[64], y=[64, 12], batch=[1220], ptr=[65])\n",
      "\n",
      "Step 15:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1373, 9], edge_index=[2, 2886], edge_attr=[2886, 3], smiles=[64], y=[64, 12], batch=[1373], ptr=[65])\n",
      "\n",
      "Step 16:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1158, 9], edge_index=[2, 2412], edge_attr=[2412, 3], smiles=[64], y=[64, 12], batch=[1158], ptr=[65])\n",
      "\n",
      "Step 17:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1095, 9], edge_index=[2, 2282], edge_attr=[2282, 3], smiles=[64], y=[64, 12], batch=[1095], ptr=[65])\n",
      "\n",
      "Step 18:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1074, 9], edge_index=[2, 2206], edge_attr=[2206, 3], smiles=[64], y=[64, 12], batch=[1074], ptr=[65])\n",
      "\n",
      "Step 19:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1158, 9], edge_index=[2, 2366], edge_attr=[2366, 3], smiles=[64], y=[64, 12], batch=[1158], ptr=[65])\n",
      "\n",
      "Step 20:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1056, 9], edge_index=[2, 2162], edge_attr=[2162, 3], smiles=[64], y=[64, 12], batch=[1056], ptr=[65])\n",
      "\n",
      "Step 21:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1202, 9], edge_index=[2, 2498], edge_attr=[2498, 3], smiles=[64], y=[64, 12], batch=[1202], ptr=[65])\n",
      "\n",
      "Step 22:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1164, 9], edge_index=[2, 2448], edge_attr=[2448, 3], smiles=[64], y=[64, 12], batch=[1164], ptr=[65])\n",
      "\n",
      "Step 23:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1015, 9], edge_index=[2, 2090], edge_attr=[2090, 3], smiles=[64], y=[64, 12], batch=[1015], ptr=[65])\n",
      "\n",
      "Step 24:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1175, 9], edge_index=[2, 2400], edge_attr=[2400, 3], smiles=[64], y=[64, 12], batch=[1175], ptr=[65])\n",
      "\n",
      "Step 25:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1124, 9], edge_index=[2, 2338], edge_attr=[2338, 3], smiles=[64], y=[64, 12], batch=[1124], ptr=[65])\n",
      "\n",
      "Step 26:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1085, 9], edge_index=[2, 2242], edge_attr=[2242, 3], smiles=[64], y=[64, 12], batch=[1085], ptr=[65])\n",
      "\n",
      "Step 27:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1236, 9], edge_index=[2, 2552], edge_attr=[2552, 3], smiles=[64], y=[64, 12], batch=[1236], ptr=[65])\n",
      "\n",
      "Step 28:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1287, 9], edge_index=[2, 2686], edge_attr=[2686, 3], smiles=[64], y=[64, 12], batch=[1287], ptr=[65])\n",
      "\n",
      "Step 29:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1175, 9], edge_index=[2, 2416], edge_attr=[2416, 3], smiles=[64], y=[64, 12], batch=[1175], ptr=[65])\n",
      "\n",
      "Step 30:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1262, 9], edge_index=[2, 2640], edge_attr=[2640, 3], smiles=[64], y=[64, 12], batch=[1262], ptr=[65])\n",
      "\n",
      "Step 31:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1248, 9], edge_index=[2, 2606], edge_attr=[2606, 3], smiles=[64], y=[64, 12], batch=[1248], ptr=[65])\n",
      "\n",
      "Step 32:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1185, 9], edge_index=[2, 2448], edge_attr=[2448, 3], smiles=[64], y=[64, 12], batch=[1185], ptr=[65])\n",
      "\n",
      "Step 33:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1166, 9], edge_index=[2, 2398], edge_attr=[2398, 3], smiles=[64], y=[64, 12], batch=[1166], ptr=[65])\n",
      "\n",
      "Step 34:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1072, 9], edge_index=[2, 2222], edge_attr=[2222, 3], smiles=[64], y=[64, 12], batch=[1072], ptr=[65])\n",
      "\n",
      "Step 35:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1240, 9], edge_index=[2, 2572], edge_attr=[2572, 3], smiles=[64], y=[64, 12], batch=[1240], ptr=[65])\n",
      "\n",
      "Step 36:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[999, 9], edge_index=[2, 2038], edge_attr=[2038, 3], smiles=[64], y=[64, 12], batch=[999], ptr=[65])\n",
      "\n",
      "Step 37:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1133, 9], edge_index=[2, 2356], edge_attr=[2356, 3], smiles=[64], y=[64, 12], batch=[1133], ptr=[65])\n",
      "\n",
      "Step 38:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1142, 9], edge_index=[2, 2366], edge_attr=[2366, 3], smiles=[64], y=[64, 12], batch=[1142], ptr=[65])\n",
      "\n",
      "Step 39:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1116, 9], edge_index=[2, 2282], edge_attr=[2282, 3], smiles=[64], y=[64, 12], batch=[1116], ptr=[65])\n",
      "\n",
      "Step 40:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1141, 9], edge_index=[2, 2362], edge_attr=[2362, 3], smiles=[64], y=[64, 12], batch=[1141], ptr=[65])\n",
      "\n",
      "Step 41:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1231, 9], edge_index=[2, 2572], edge_attr=[2572, 3], smiles=[64], y=[64, 12], batch=[1231], ptr=[65])\n",
      "\n",
      "Step 42:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1226, 9], edge_index=[2, 2554], edge_attr=[2554, 3], smiles=[64], y=[64, 12], batch=[1226], ptr=[65])\n",
      "\n",
      "Step 43:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1061, 9], edge_index=[2, 2178], edge_attr=[2178, 3], smiles=[64], y=[64, 12], batch=[1061], ptr=[65])\n",
      "\n",
      "Step 44:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1072, 9], edge_index=[2, 2222], edge_attr=[2222, 3], smiles=[64], y=[64, 12], batch=[1072], ptr=[65])\n",
      "\n",
      "Step 45:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1183, 9], edge_index=[2, 2468], edge_attr=[2468, 3], smiles=[64], y=[64, 12], batch=[1183], ptr=[65])\n",
      "\n",
      "Step 46:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1236, 9], edge_index=[2, 2580], edge_attr=[2580, 3], smiles=[64], y=[64, 12], batch=[1236], ptr=[65])\n",
      "\n",
      "Step 47:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1260, 9], edge_index=[2, 2632], edge_attr=[2632, 3], smiles=[64], y=[64, 12], batch=[1260], ptr=[65])\n",
      "\n",
      "Step 48:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1119, 9], edge_index=[2, 2300], edge_attr=[2300, 3], smiles=[64], y=[64, 12], batch=[1119], ptr=[65])\n",
      "\n",
      "Step 49:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1180, 9], edge_index=[2, 2440], edge_attr=[2440, 3], smiles=[64], y=[64, 12], batch=[1180], ptr=[65])\n",
      "\n",
      "Step 50:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1278, 9], edge_index=[2, 2682], edge_attr=[2682, 3], smiles=[64], y=[64, 12], batch=[1278], ptr=[65])\n",
      "\n",
      "Step 51:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1140, 9], edge_index=[2, 2402], edge_attr=[2402, 3], smiles=[64], y=[64, 12], batch=[1140], ptr=[65])\n",
      "\n",
      "Step 52:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1329, 9], edge_index=[2, 2786], edge_attr=[2786, 3], smiles=[64], y=[64, 12], batch=[1329], ptr=[65])\n",
      "\n",
      "Step 53:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1180, 9], edge_index=[2, 2438], edge_attr=[2438, 3], smiles=[64], y=[64, 12], batch=[1180], ptr=[65])\n",
      "\n",
      "Step 54:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1231, 9], edge_index=[2, 2534], edge_attr=[2534, 3], smiles=[64], y=[64, 12], batch=[1231], ptr=[65])\n",
      "\n",
      "Step 55:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1150, 9], edge_index=[2, 2384], edge_attr=[2384, 3], smiles=[64], y=[64, 12], batch=[1150], ptr=[65])\n",
      "\n",
      "Step 56:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1199, 9], edge_index=[2, 2506], edge_attr=[2506, 3], smiles=[64], y=[64, 12], batch=[1199], ptr=[65])\n",
      "\n",
      "Step 57:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1081, 9], edge_index=[2, 2232], edge_attr=[2232, 3], smiles=[64], y=[64, 12], batch=[1081], ptr=[65])\n",
      "\n",
      "Step 58:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1251, 9], edge_index=[2, 2592], edge_attr=[2592, 3], smiles=[64], y=[64, 12], batch=[1251], ptr=[65])\n",
      "\n",
      "Step 59:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1192, 9], edge_index=[2, 2474], edge_attr=[2474, 3], smiles=[64], y=[64, 12], batch=[1192], ptr=[65])\n",
      "\n",
      "Step 60:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1155, 9], edge_index=[2, 2420], edge_attr=[2420, 3], smiles=[64], y=[64, 12], batch=[1155], ptr=[65])\n",
      "\n",
      "Step 61:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1087, 9], edge_index=[2, 2238], edge_attr=[2238, 3], smiles=[64], y=[64, 12], batch=[1087], ptr=[65])\n",
      "\n",
      "Step 62:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1193, 9], edge_index=[2, 2494], edge_attr=[2494, 3], smiles=[64], y=[64, 12], batch=[1193], ptr=[65])\n",
      "\n",
      "Step 63:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1309, 9], edge_index=[2, 2748], edge_attr=[2748, 3], smiles=[64], y=[64, 12], batch=[1309], ptr=[65])\n",
      "\n",
      "Step 64:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1195, 9], edge_index=[2, 2500], edge_attr=[2500, 3], smiles=[64], y=[64, 12], batch=[1195], ptr=[65])\n",
      "\n",
      "Step 65:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1229, 9], edge_index=[2, 2560], edge_attr=[2560, 3], smiles=[64], y=[64, 12], batch=[1229], ptr=[65])\n",
      "\n",
      "Step 66:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1226, 9], edge_index=[2, 2560], edge_attr=[2560, 3], smiles=[64], y=[64, 12], batch=[1226], ptr=[65])\n",
      "\n",
      "Step 67:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1355, 9], edge_index=[2, 2846], edge_attr=[2846, 3], smiles=[64], y=[64, 12], batch=[1355], ptr=[65])\n",
      "\n",
      "Step 68:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1183, 9], edge_index=[2, 2460], edge_attr=[2460, 3], smiles=[64], y=[64, 12], batch=[1183], ptr=[65])\n",
      "\n",
      "Step 69:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1203, 9], edge_index=[2, 2516], edge_attr=[2516, 3], smiles=[64], y=[64, 12], batch=[1203], ptr=[65])\n",
      "\n",
      "Step 70:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1482, 9], edge_index=[2, 3130], edge_attr=[3130, 3], smiles=[64], y=[64, 12], batch=[1482], ptr=[65])\n",
      "\n",
      "Step 71:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1158, 9], edge_index=[2, 2364], edge_attr=[2364, 3], smiles=[64], y=[64, 12], batch=[1158], ptr=[65])\n",
      "\n",
      "Step 72:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1005, 9], edge_index=[2, 2042], edge_attr=[2042, 3], smiles=[64], y=[64, 12], batch=[1005], ptr=[65])\n",
      "\n",
      "Step 73:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1219, 9], edge_index=[2, 2524], edge_attr=[2524, 3], smiles=[64], y=[64, 12], batch=[1219], ptr=[65])\n",
      "\n",
      "Step 74:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1207, 9], edge_index=[2, 2518], edge_attr=[2518, 3], smiles=[64], y=[64, 12], batch=[1207], ptr=[65])\n",
      "\n",
      "Step 75:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1366, 9], edge_index=[2, 2860], edge_attr=[2860, 3], smiles=[64], y=[64, 12], batch=[1366], ptr=[65])\n",
      "\n",
      "Step 76:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1124, 9], edge_index=[2, 2344], edge_attr=[2344, 3], smiles=[64], y=[64, 12], batch=[1124], ptr=[65])\n",
      "\n",
      "Step 77:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1107, 9], edge_index=[2, 2294], edge_attr=[2294, 3], smiles=[64], y=[64, 12], batch=[1107], ptr=[65])\n",
      "\n",
      "Step 78:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1330, 9], edge_index=[2, 2788], edge_attr=[2788, 3], smiles=[64], y=[64, 12], batch=[1330], ptr=[65])\n",
      "\n",
      "Step 79:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1199, 9], edge_index=[2, 2510], edge_attr=[2510, 3], smiles=[64], y=[64, 12], batch=[1199], ptr=[65])\n",
      "\n",
      "Step 80:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1238, 9], edge_index=[2, 2542], edge_attr=[2542, 3], smiles=[64], y=[64, 12], batch=[1238], ptr=[65])\n",
      "\n",
      "Step 81:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1336, 9], edge_index=[2, 2816], edge_attr=[2816, 3], smiles=[64], y=[64, 12], batch=[1336], ptr=[65])\n",
      "\n",
      "Step 82:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1094, 9], edge_index=[2, 2284], edge_attr=[2284, 3], smiles=[64], y=[64, 12], batch=[1094], ptr=[65])\n",
      "\n",
      "Step 83:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1263, 9], edge_index=[2, 2632], edge_attr=[2632, 3], smiles=[64], y=[64, 12], batch=[1263], ptr=[65])\n",
      "\n",
      "Step 84:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1128, 9], edge_index=[2, 2320], edge_attr=[2320, 3], smiles=[64], y=[64, 12], batch=[1128], ptr=[65])\n",
      "\n",
      "Step 85:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1141, 9], edge_index=[2, 2344], edge_attr=[2344, 3], smiles=[64], y=[64, 12], batch=[1141], ptr=[65])\n",
      "\n",
      "Step 86:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1199, 9], edge_index=[2, 2500], edge_attr=[2500, 3], smiles=[64], y=[64, 12], batch=[1199], ptr=[65])\n",
      "\n",
      "Step 87:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1129, 9], edge_index=[2, 2370], edge_attr=[2370, 3], smiles=[64], y=[64, 12], batch=[1129], ptr=[65])\n",
      "\n",
      "Step 88:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1219, 9], edge_index=[2, 2556], edge_attr=[2556, 3], smiles=[64], y=[64, 12], batch=[1219], ptr=[65])\n",
      "\n",
      "Step 89:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1133, 9], edge_index=[2, 2336], edge_attr=[2336, 3], smiles=[64], y=[64, 12], batch=[1133], ptr=[65])\n",
      "\n",
      "Step 90:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1130, 9], edge_index=[2, 2362], edge_attr=[2362, 3], smiles=[64], y=[64, 12], batch=[1130], ptr=[65])\n",
      "\n",
      "Step 91:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1186, 9], edge_index=[2, 2454], edge_attr=[2454, 3], smiles=[64], y=[64, 12], batch=[1186], ptr=[65])\n",
      "\n",
      "Step 92:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1157, 9], edge_index=[2, 2408], edge_attr=[2408, 3], smiles=[64], y=[64, 12], batch=[1157], ptr=[65])\n",
      "\n",
      "Step 93:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1264, 9], edge_index=[2, 2644], edge_attr=[2644, 3], smiles=[64], y=[64, 12], batch=[1264], ptr=[65])\n",
      "\n",
      "Step 94:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1199, 9], edge_index=[2, 2474], edge_attr=[2474, 3], smiles=[64], y=[64, 12], batch=[1199], ptr=[65])\n",
      "\n",
      "Step 95:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1076, 9], edge_index=[2, 2200], edge_attr=[2200, 3], smiles=[64], y=[64, 12], batch=[1076], ptr=[65])\n",
      "\n",
      "Step 96:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1140, 9], edge_index=[2, 2352], edge_attr=[2352, 3], smiles=[64], y=[64, 12], batch=[1140], ptr=[65])\n",
      "\n",
      "Step 97:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1294, 9], edge_index=[2, 2708], edge_attr=[2708, 3], smiles=[64], y=[64, 12], batch=[1294], ptr=[65])\n",
      "\n",
      "Step 98:\n",
      "=======\n",
      "Number of graphs in the current batch: 56\n",
      "DataBatch(x=[1167, 9], edge_index=[2, 2448], edge_attr=[2448, 3], smiles=[56], y=[56, 12], batch=[1167], ptr=[57])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "for step, data in enumerate(train_loader):\n",
    "    print(f'Step {step + 1}:')\n",
    "    print('=======')\n",
    "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "    print(data)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mini-batch data âœ…\n",
    "\n",
    "Next step: Graph. Neural. Networks.\n",
    "\n",
    "FINALLY. Let's make like Merriam-Webster and define what our GNN is going to look like.\n",
    "\n",
    "But before we that, let's quickly review message-passing (you're welcome, future me)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN(\n",
      "  (conv1): GraphConv(9, 64)\n",
      "  (conv2): GraphConv(64, 64)\n",
      "  (conv3): GraphConv(64, 64)\n",
      "  (lin): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GraphConv\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GNN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GraphConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2 = GraphConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GraphConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, 2)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = GNN(hidden_channels=64)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "        loss = loss_fn(out, data.y[:, column_index_to_check])  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "def test(loader):\n",
    "     model.eval()\n",
    "\n",
    "     correct = 0\n",
    "     for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "         out = model(data.x, data.edge_index, data.batch)  \n",
    "         pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "         correct += int((pred == data.y[:, column_index_to_check]).sum())  # Check against ground-truth labels.\n",
    "     return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 0.9025, Test Acc: 0.9004\n",
      "Epoch: 002, Train Acc: 0.9023, Test Acc: 0.9004\n",
      "Epoch: 003, Train Acc: 0.9023, Test Acc: 0.9004\n",
      "Epoch: 004, Train Acc: 0.9023, Test Acc: 0.9004\n",
      "Epoch: 005, Train Acc: 0.9023, Test Acc: 0.9004\n",
      "Epoch: 006, Train Acc: 0.9023, Test Acc: 0.9004\n",
      "Epoch: 007, Train Acc: 0.9023, Test Acc: 0.9004\n",
      "Epoch: 008, Train Acc: 0.9023, Test Acc: 0.9004\n",
      "Epoch: 009, Train Acc: 0.9023, Test Acc: 0.9004\n",
      "Epoch: 010, Train Acc: 0.9023, Test Acc: 0.9004\n",
      "Epoch: 011, Train Acc: 0.9023, Test Acc: 0.9004\n",
      "Epoch: 012, Train Acc: 0.9023, Test Acc: 0.9004\n",
      "Epoch: 013, Train Acc: 0.9023, Test Acc: 0.9004\n",
      "Epoch: 014, Train Acc: 0.9023, Test Acc: 0.9004\n",
      "Epoch: 015, Train Acc: 0.9023, Test Acc: 0.9004\n",
      "Epoch: 016, Train Acc: 0.9023, Test Acc: 0.9004\n",
      "Epoch: 017, Train Acc: 0.9026, Test Acc: 0.9004\n",
      "Epoch: 018, Train Acc: 0.9023, Test Acc: 0.9004\n",
      "Epoch: 019, Train Acc: 0.9031, Test Acc: 0.9017\n",
      "Epoch: 020, Train Acc: 0.9052, Test Acc: 0.9017\n",
      "Epoch: 021, Train Acc: 0.9036, Test Acc: 0.9036\n",
      "Epoch: 022, Train Acc: 0.9028, Test Acc: 0.9004\n",
      "Epoch: 023, Train Acc: 0.9050, Test Acc: 0.9043\n",
      "Epoch: 024, Train Acc: 0.9047, Test Acc: 0.9011\n",
      "Epoch: 025, Train Acc: 0.9045, Test Acc: 0.9017\n",
      "Epoch: 026, Train Acc: 0.9023, Test Acc: 0.9004\n",
      "Epoch: 027, Train Acc: 0.9063, Test Acc: 0.9056\n",
      "Epoch: 028, Train Acc: 0.9061, Test Acc: 0.9030\n",
      "Epoch: 029, Train Acc: 0.9072, Test Acc: 0.9024\n",
      "Epoch: 030, Train Acc: 0.9064, Test Acc: 0.8998\n",
      "Epoch: 031, Train Acc: 0.9053, Test Acc: 0.9056\n",
      "Epoch: 032, Train Acc: 0.9055, Test Acc: 0.9030\n",
      "Epoch: 033, Train Acc: 0.9055, Test Acc: 0.8998\n",
      "Epoch: 034, Train Acc: 0.9023, Test Acc: 0.9004\n",
      "Epoch: 035, Train Acc: 0.9049, Test Acc: 0.9011\n",
      "Epoch: 036, Train Acc: 0.9050, Test Acc: 0.9017\n",
      "Epoch: 037, Train Acc: 0.9037, Test Acc: 0.9036\n",
      "Epoch: 038, Train Acc: 0.9025, Test Acc: 0.9004\n",
      "Epoch: 039, Train Acc: 0.9026, Test Acc: 0.9017\n",
      "Epoch: 040, Train Acc: 0.9023, Test Acc: 0.9011\n",
      "Epoch: 041, Train Acc: 0.9045, Test Acc: 0.9030\n",
      "Epoch: 042, Train Acc: 0.9071, Test Acc: 0.9030\n",
      "Epoch: 043, Train Acc: 0.9063, Test Acc: 0.8966\n",
      "Epoch: 044, Train Acc: 0.9044, Test Acc: 0.8960\n",
      "Epoch: 045, Train Acc: 0.9034, Test Acc: 0.9024\n",
      "Epoch: 046, Train Acc: 0.8985, Test Acc: 0.8973\n",
      "Epoch: 047, Train Acc: 0.9061, Test Acc: 0.9043\n",
      "Epoch: 048, Train Acc: 0.9071, Test Acc: 0.9011\n",
      "Epoch: 049, Train Acc: 0.9069, Test Acc: 0.8966\n",
      "Epoch: 050, Train Acc: 0.9063, Test Acc: 0.9030\n",
      "Epoch: 051, Train Acc: 0.9080, Test Acc: 0.9043\n",
      "Epoch: 052, Train Acc: 0.9041, Test Acc: 0.9036\n",
      "Epoch: 053, Train Acc: 0.9026, Test Acc: 0.9017\n",
      "Epoch: 054, Train Acc: 0.9023, Test Acc: 0.9004\n",
      "Epoch: 055, Train Acc: 0.9023, Test Acc: 0.9004\n",
      "Epoch: 056, Train Acc: 0.9023, Test Acc: 0.9004\n",
      "Epoch: 057, Train Acc: 0.9068, Test Acc: 0.9024\n",
      "Epoch: 058, Train Acc: 0.9074, Test Acc: 0.8979\n",
      "Epoch: 059, Train Acc: 0.9076, Test Acc: 0.9030\n",
      "Epoch: 060, Train Acc: 0.9050, Test Acc: 0.8979\n",
      "Epoch: 061, Train Acc: 0.9077, Test Acc: 0.9024\n",
      "Epoch: 062, Train Acc: 0.9055, Test Acc: 0.9049\n",
      "Epoch: 063, Train Acc: 0.9076, Test Acc: 0.8992\n",
      "Epoch: 064, Train Acc: 0.9087, Test Acc: 0.9017\n",
      "Epoch: 065, Train Acc: 0.9076, Test Acc: 0.8992\n",
      "Epoch: 066, Train Acc: 0.9023, Test Acc: 0.9004\n",
      "Epoch: 067, Train Acc: 0.9044, Test Acc: 0.9036\n",
      "Epoch: 068, Train Acc: 0.9033, Test Acc: 0.9024\n",
      "Epoch: 069, Train Acc: 0.9023, Test Acc: 0.9004\n",
      "Epoch: 070, Train Acc: 0.9058, Test Acc: 0.9043\n",
      "Epoch: 071, Train Acc: 0.9061, Test Acc: 0.8998\n",
      "Epoch: 072, Train Acc: 0.9064, Test Acc: 0.9056\n",
      "Epoch: 073, Train Acc: 0.9079, Test Acc: 0.9024\n",
      "Epoch: 074, Train Acc: 0.9044, Test Acc: 0.8966\n",
      "Epoch: 075, Train Acc: 0.8997, Test Acc: 0.8909\n",
      "Epoch: 076, Train Acc: 0.9072, Test Acc: 0.9004\n",
      "Epoch: 077, Train Acc: 0.9068, Test Acc: 0.9062\n",
      "Epoch: 078, Train Acc: 0.9063, Test Acc: 0.9062\n",
      "Epoch: 079, Train Acc: 0.8713, Test Acc: 0.8730\n",
      "Epoch: 080, Train Acc: 0.9047, Test Acc: 0.9030\n",
      "Epoch: 081, Train Acc: 0.9063, Test Acc: 0.9036\n",
      "Epoch: 082, Train Acc: 0.9061, Test Acc: 0.9030\n",
      "Epoch: 083, Train Acc: 0.9061, Test Acc: 0.9043\n",
      "Epoch: 084, Train Acc: 0.9015, Test Acc: 0.8998\n",
      "Epoch: 085, Train Acc: 0.9033, Test Acc: 0.8985\n",
      "Epoch: 086, Train Acc: 0.9037, Test Acc: 0.9056\n",
      "Epoch: 087, Train Acc: 0.9039, Test Acc: 0.9024\n",
      "Epoch: 088, Train Acc: 0.9053, Test Acc: 0.9030\n",
      "Epoch: 089, Train Acc: 0.9064, Test Acc: 0.9043\n",
      "Epoch: 090, Train Acc: 0.9069, Test Acc: 0.9024\n",
      "Epoch: 091, Train Acc: 0.9045, Test Acc: 0.9024\n",
      "Epoch: 092, Train Acc: 0.9049, Test Acc: 0.9036\n",
      "Epoch: 093, Train Acc: 0.9082, Test Acc: 0.9036\n",
      "Epoch: 094, Train Acc: 0.9023, Test Acc: 0.9004\n",
      "Epoch: 095, Train Acc: 0.9074, Test Acc: 0.9024\n",
      "Epoch: 096, Train Acc: 0.9053, Test Acc: 0.9043\n",
      "Epoch: 097, Train Acc: 0.9029, Test Acc: 0.9004\n",
      "Epoch: 098, Train Acc: 0.9060, Test Acc: 0.8985\n",
      "Epoch: 099, Train Acc: 0.9068, Test Acc: 0.9011\n",
      "Epoch: 100, Train Acc: 0.9049, Test Acc: 0.9030\n",
      "Epoch: 101, Train Acc: 0.9085, Test Acc: 0.9030\n",
      "Epoch: 102, Train Acc: 0.9050, Test Acc: 0.9030\n",
      "Epoch: 103, Train Acc: 0.9052, Test Acc: 0.9030\n",
      "Epoch: 104, Train Acc: 0.9072, Test Acc: 0.9043\n",
      "Epoch: 105, Train Acc: 0.9079, Test Acc: 0.8992\n",
      "Epoch: 106, Train Acc: 0.9039, Test Acc: 0.8979\n",
      "Epoch: 107, Train Acc: 0.9106, Test Acc: 0.8985\n",
      "Epoch: 108, Train Acc: 0.9041, Test Acc: 0.9004\n",
      "Epoch: 109, Train Acc: 0.9079, Test Acc: 0.9024\n",
      "Epoch: 110, Train Acc: 0.9041, Test Acc: 0.9024\n",
      "Epoch: 111, Train Acc: 0.9082, Test Acc: 0.9030\n",
      "Epoch: 112, Train Acc: 0.9031, Test Acc: 0.9017\n",
      "Epoch: 113, Train Acc: 0.9087, Test Acc: 0.9011\n",
      "Epoch: 114, Train Acc: 0.9063, Test Acc: 0.8998\n",
      "Epoch: 115, Train Acc: 0.9074, Test Acc: 0.9030\n",
      "Epoch: 116, Train Acc: 0.9077, Test Acc: 0.9068\n",
      "Epoch: 117, Train Acc: 0.9047, Test Acc: 0.8998\n",
      "Epoch: 118, Train Acc: 0.9039, Test Acc: 0.8947\n",
      "Epoch: 119, Train Acc: 0.9074, Test Acc: 0.9036\n",
      "Epoch: 120, Train Acc: 0.9085, Test Acc: 0.8992\n",
      "Epoch: 121, Train Acc: 0.9063, Test Acc: 0.8979\n",
      "Epoch: 122, Train Acc: 0.9033, Test Acc: 0.9017\n",
      "Epoch: 123, Train Acc: 0.9076, Test Acc: 0.9024\n",
      "Epoch: 124, Train Acc: 0.9050, Test Acc: 0.9043\n",
      "Epoch: 125, Train Acc: 0.9057, Test Acc: 0.9056\n",
      "Epoch: 126, Train Acc: 0.9063, Test Acc: 0.8947\n",
      "Epoch: 127, Train Acc: 0.9098, Test Acc: 0.9004\n",
      "Epoch: 128, Train Acc: 0.9072, Test Acc: 0.9056\n",
      "Epoch: 129, Train Acc: 0.9052, Test Acc: 0.9030\n",
      "Epoch: 130, Train Acc: 0.9071, Test Acc: 0.9056\n",
      "Epoch: 131, Train Acc: 0.9077, Test Acc: 0.9024\n",
      "Epoch: 132, Train Acc: 0.9069, Test Acc: 0.9056\n",
      "Epoch: 133, Train Acc: 0.9041, Test Acc: 0.8909\n",
      "Epoch: 134, Train Acc: 0.9047, Test Acc: 0.9036\n",
      "Epoch: 135, Train Acc: 0.9069, Test Acc: 0.9030\n",
      "Epoch: 136, Train Acc: 0.9044, Test Acc: 0.9030\n",
      "Epoch: 137, Train Acc: 0.9053, Test Acc: 0.9049\n",
      "Epoch: 138, Train Acc: 0.9084, Test Acc: 0.8998\n",
      "Epoch: 139, Train Acc: 0.8997, Test Acc: 0.8947\n",
      "Epoch: 140, Train Acc: 0.9064, Test Acc: 0.9024\n",
      "Epoch: 141, Train Acc: 0.9085, Test Acc: 0.9017\n",
      "Epoch: 142, Train Acc: 0.9033, Test Acc: 0.9011\n",
      "Epoch: 143, Train Acc: 0.9039, Test Acc: 0.9036\n",
      "Epoch: 144, Train Acc: 0.9087, Test Acc: 0.9036\n",
      "Epoch: 145, Train Acc: 0.9060, Test Acc: 0.9036\n",
      "Epoch: 146, Train Acc: 0.9079, Test Acc: 0.9030\n",
      "Epoch: 147, Train Acc: 0.9036, Test Acc: 0.9011\n",
      "Epoch: 148, Train Acc: 0.9023, Test Acc: 0.9004\n",
      "Epoch: 149, Train Acc: 0.9026, Test Acc: 0.9011\n",
      "Epoch: 150, Train Acc: 0.9023, Test Acc: 0.9004\n",
      "Epoch: 151, Train Acc: 0.9088, Test Acc: 0.9030\n",
      "Epoch: 152, Train Acc: 0.9023, Test Acc: 0.9004\n",
      "Epoch: 153, Train Acc: 0.9093, Test Acc: 0.9043\n",
      "Epoch: 154, Train Acc: 0.9042, Test Acc: 0.9030\n",
      "Epoch: 155, Train Acc: 0.9028, Test Acc: 0.8998\n",
      "Epoch: 156, Train Acc: 0.9025, Test Acc: 0.9011\n",
      "Epoch: 157, Train Acc: 0.9087, Test Acc: 0.9049\n",
      "Epoch: 158, Train Acc: 0.9087, Test Acc: 0.8979\n",
      "Epoch: 159, Train Acc: 0.9069, Test Acc: 0.8998\n",
      "Epoch: 160, Train Acc: 0.9037, Test Acc: 0.9062\n",
      "Epoch: 161, Train Acc: 0.9060, Test Acc: 0.9056\n",
      "Epoch: 162, Train Acc: 0.9033, Test Acc: 0.9017\n",
      "Epoch: 163, Train Acc: 0.9072, Test Acc: 0.9049\n",
      "Epoch: 164, Train Acc: 0.9079, Test Acc: 0.9056\n",
      "Epoch: 165, Train Acc: 0.9077, Test Acc: 0.8998\n",
      "Epoch: 166, Train Acc: 0.9071, Test Acc: 0.9036\n",
      "Epoch: 167, Train Acc: 0.9002, Test Acc: 0.8941\n",
      "Epoch: 168, Train Acc: 0.9057, Test Acc: 0.9056\n",
      "Epoch: 169, Train Acc: 0.9052, Test Acc: 0.9049\n",
      "Epoch: 170, Train Acc: 0.9041, Test Acc: 0.9024\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 171):\n",
    "    train()\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
