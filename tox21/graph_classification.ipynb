{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Okay. Alright. That's fine.*\n",
    "\n",
    "\\- Drake\n",
    "\n",
    "\n",
    "\n",
    "Hyperparameter optimization did not as expected, but we have more exciting things ahead of us: creating our own graph classifier. Let's approach this task using PyTorch Geometric using this [example](https://colab.research.google.com/drive/1I8a0DfQ3fI7Njc62__mVXUlcAleUclnb?usp=sharing#scrollTo=mHSP6-RBOqCE) as reference.\n",
    "\n",
    "We can break this down into a few steps:\n",
    "- Convert SMILES data into graph data\n",
    "- Mini-batch graph data\n",
    "- Define Graph Neural Network for graph classification\n",
    "- Train model and evaluate - you know the drill \n",
    "\n",
    "Let's get to it ðŸ¤–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install deepchem\n",
    "!pip install 'deepchem[torch]'\n",
    "!pip install rdkit\n",
    "!pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/mihirarya/Dev/bcil/tox21/env/lib/python3.10/site-packages/tensorflow/python/util/deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_relax_shapes is deprecated, use reduce_retracing instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n",
      "[11:43:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[11:43:20] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "import deepchem as dc\n",
    "\n",
    "tasks, datasets, transformers = dc.molnet.load_tox21(featurizer='GraphConv', reload=False)\n",
    "train_dataset, valid_dataset, test_dataset = datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a close look at this dataset by inspecting the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DiskDataset X.shape: (6264,), y.shape: (6264, 12), w.shape: (6264, 12), task_names: ['NR-AR' 'NR-AR-LBD' 'NR-AhR' ... 'SR-HSE' 'SR-MMP' 'SR-p53']>\n",
      "[<deepchem.feat.mol_graphs.ConvMol object at 0x105a40700>\n",
      " <deepchem.feat.mol_graphs.ConvMol object at 0x2cf06cbb0>\n",
      " <deepchem.feat.mol_graphs.ConvMol object at 0x2cf06d3c0> ...\n",
      " <deepchem.feat.mol_graphs.ConvMol object at 0x2cdd98790>\n",
      " <deepchem.feat.mol_graphs.ConvMol object at 0x2cdd990f0>\n",
      " <deepchem.feat.mol_graphs.ConvMol object at 0x2cdd997e0>]\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)\n",
    "print(train_dataset.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there are **6264** graphs (molecules) in our training dataset, where *X* stores the molecules as ConvMol objects, *y* stores the hot-encoded output vector with one entry for each of the **12** measures/tasks, and a weights matrix *w*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's one particular molecule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This molecule has 11 atoms with 75 features each.\n"
     ]
    }
   ],
   "source": [
    "test_mol = train_dataset.X[0]\n",
    "print(f\"This molecule has {test_mol.n_atoms} atoms with {test_mol.n_feat} features each.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6264, 783, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(valid_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note above sizes of our training, validation, and test datasets. However, we can't just operate on the above data directly as molecular information is stored as a [SMILES](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) string (that is, simplified molecular-input line-entry system). Try saying that five times fast. In short, the specification enables structural information of molecules to be encoded into a string.\n",
    "\n",
    "For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CC(O)(P(=O)(O)O)P(=O)(O)O'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.ids[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, open-source is once again our savior: [SciPy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.spmatrix.html) supplies a few helper functions to convert sparse adjacency matrices  into graph data that we *can* use with PyTorch Geometric. From there, we can extract additional metadata to help understand the numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "import numpy as np\n",
    "def adjacency_list_to_sparse(adj_list):\n",
    "    num_nodes = len(adj_list)\n",
    "    rows, cols = [], []\n",
    "\n",
    "    for i, neighbors in enumerate(adj_list):\n",
    "        rows.extend([i] * len(neighbors))\n",
    "        cols.extend(neighbors)\n",
    "\n",
    "    adjacency_matrix = scipy.sparse.coo_matrix((np.ones_like(rows), (rows, cols)),\n",
    "                                              shape=(num_nodes, num_nodes),\n",
    "                                              dtype=np.float32)\n",
    "\n",
    "    return adjacency_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from torch_geometric.utils.convert import from_scipy_sparse_matrix\n",
    "\n",
    "\n",
    "def to_data(mol_graph):\n",
    "\n",
    "    x = mol_graph.get_atom_features()\n",
    "\n",
    "    adj_list = mol_graph.get_adjacency_list()\n",
    "    sparse_mat = adjacency_list_to_sparse(adj_list)\n",
    "    edge_index, edge_attr = from_scipy_sparse_matrix(sparse_mat)\n",
    "    \n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little clarification on the `Data` object might help:\n",
    "\n",
    "1. **x (Node Feature Matrix):**\n",
    "   - This parameter represents the feature matrix for each node in the graph.\n",
    "   - It is a PyTorch tensor with shape [num_nodes, num_node_features].\n",
    "   - Each row corresponds to a node, and each column corresponds to a feature of that node.\n",
    "   - For example, if you are representing atoms in a molecule, `x` could contain features like atomic number, charge, etc.\n",
    "\n",
    "\n",
    "2. **edge_index (Graph Connectivity):**\n",
    "   - `edge_index` represents the graph connectivity in COO (Coordinate List) format.\n",
    "   - It is a PyTorch tensor with shape [2, num_edges].\n",
    "   - Each column of `edge_index` contains the indices of two nodes that form an edge.\n",
    "   - For an undirected graph, (i, j) and (j, i) should both be present in the `edge_index`.\n",
    "\n",
    "\n",
    "3. **edge_attr (Edge Feature Matrix):**\n",
    "   - `edge_attr` represents the feature matrix for each edge in the graph.\n",
    "   - It is a PyTorch tensor with shape [num_edges, num_edge_features].\n",
    "   - Each row corresponds to an edge, and each column corresponds to a feature of that edge.\n",
    "   - This is often used to store information like bond types, distances, or any other edge-specific features.\n",
    "\n",
    "While there are a few other parameters, these three collectively provide a comprehensive representation of the graph needed for our specific use case.\n",
    "\n",
    "Let's convert all our datasets from ConvMol to Data objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_graph = []\n",
    "for mol_graph in train_dataset.X:\n",
    "    data = to_data(mol_graph)\n",
    "    train_dataset_graph.append(data)\n",
    "\n",
    "valid_dataset_graph = []\n",
    "for mol_graph in valid_dataset.X:\n",
    "    data = to_data(mol_graph)\n",
    "    valid_dataset_graph.append(data)\n",
    "\n",
    "test_dataset_graph = []\n",
    "for mol_graph in test_dataset.X:\n",
    "    data = to_data(mol_graph)\n",
    "    test_dataset_graph.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[11, 75], edge_index=[2, 20], edge_attr=[20])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_graph[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "train_loader = DataLoader(train_dataset_graph, batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset_graph, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 1942], edge_attr=[1942], batch=[960], ptr=[65])\n",
      "\n",
      "Step 2:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2308], edge_attr=[2308], batch=[1127], ptr=[65])\n",
      "\n",
      "Step 3:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 1990], edge_attr=[1990], batch=[978], ptr=[65])\n",
      "\n",
      "Step 4:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2006], edge_attr=[2006], batch=[993], ptr=[65])\n",
      "\n",
      "Step 5:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2062], edge_attr=[2062], batch=[1025], ptr=[65])\n",
      "\n",
      "Step 6:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2102], edge_attr=[2102], batch=[1037], ptr=[65])\n",
      "\n",
      "Step 7:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2316], edge_attr=[2316], batch=[1120], ptr=[65])\n",
      "\n",
      "Step 8:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2024], edge_attr=[2024], batch=[988], ptr=[65])\n",
      "\n",
      "Step 9:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2122], edge_attr=[2122], batch=[1035], ptr=[65])\n",
      "\n",
      "Step 10:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2186], edge_attr=[2186], batch=[1070], ptr=[65])\n",
      "\n",
      "Step 11:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2068], edge_attr=[2068], batch=[1016], ptr=[65])\n",
      "\n",
      "Step 12:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2378], edge_attr=[2378], batch=[1149], ptr=[65])\n",
      "\n",
      "Step 13:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2220], edge_attr=[2220], batch=[1091], ptr=[65])\n",
      "\n",
      "Step 14:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 1966], edge_attr=[1966], batch=[980], ptr=[65])\n",
      "\n",
      "Step 15:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2240], edge_attr=[2240], batch=[1095], ptr=[65])\n",
      "\n",
      "Step 16:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2180], edge_attr=[2180], batch=[1064], ptr=[65])\n",
      "\n",
      "Step 17:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2242], edge_attr=[2242], batch=[1091], ptr=[65])\n",
      "\n",
      "Step 18:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 1812], edge_attr=[1812], batch=[892], ptr=[65])\n",
      "\n",
      "Step 19:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2280], edge_attr=[2280], batch=[1105], ptr=[65])\n",
      "\n",
      "Step 20:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2514], edge_attr=[2514], batch=[1229], ptr=[65])\n",
      "\n",
      "Step 21:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 1976], edge_attr=[1976], batch=[972], ptr=[65])\n",
      "\n",
      "Step 22:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2154], edge_attr=[2154], batch=[1047], ptr=[65])\n",
      "\n",
      "Step 23:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2426], edge_attr=[2426], batch=[1190], ptr=[65])\n",
      "\n",
      "Step 24:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2140], edge_attr=[2140], batch=[1046], ptr=[65])\n",
      "\n",
      "Step 25:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2186], edge_attr=[2186], batch=[1072], ptr=[65])\n",
      "\n",
      "Step 26:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 1936], edge_attr=[1936], batch=[957], ptr=[65])\n",
      "\n",
      "Step 27:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2076], edge_attr=[2076], batch=[1022], ptr=[65])\n",
      "\n",
      "Step 28:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2298], edge_attr=[2298], batch=[1134], ptr=[65])\n",
      "\n",
      "Step 29:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2200], edge_attr=[2200], batch=[1079], ptr=[65])\n",
      "\n",
      "Step 30:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2028], edge_attr=[2028], batch=[1010], ptr=[65])\n",
      "\n",
      "Step 31:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2094], edge_attr=[2094], batch=[1031], ptr=[65])\n",
      "\n",
      "Step 32:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2292], edge_attr=[2292], batch=[1128], ptr=[65])\n",
      "\n",
      "Step 33:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 1942], edge_attr=[1942], batch=[968], ptr=[65])\n",
      "\n",
      "Step 34:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2052], edge_attr=[2052], batch=[1010], ptr=[65])\n",
      "\n",
      "Step 35:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 1978], edge_attr=[1978], batch=[986], ptr=[65])\n",
      "\n",
      "Step 36:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2244], edge_attr=[2244], batch=[1097], ptr=[65])\n",
      "\n",
      "Step 37:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2154], edge_attr=[2154], batch=[1058], ptr=[65])\n",
      "\n",
      "Step 38:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 1934], edge_attr=[1934], batch=[953], ptr=[65])\n",
      "\n",
      "Step 39:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2158], edge_attr=[2158], batch=[1051], ptr=[65])\n",
      "\n",
      "Step 40:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2044], edge_attr=[2044], batch=[1017], ptr=[65])\n",
      "\n",
      "Step 41:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 1968], edge_attr=[1968], batch=[962], ptr=[65])\n",
      "\n",
      "Step 42:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2262], edge_attr=[2262], batch=[1107], ptr=[65])\n",
      "\n",
      "Step 43:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2488], edge_attr=[2488], batch=[1206], ptr=[65])\n",
      "\n",
      "Step 44:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2098], edge_attr=[2098], batch=[1029], ptr=[65])\n",
      "\n",
      "Step 45:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2100], edge_attr=[2100], batch=[1023], ptr=[65])\n",
      "\n",
      "Step 46:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2080], edge_attr=[2080], batch=[1012], ptr=[65])\n",
      "\n",
      "Step 47:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2336], edge_attr=[2336], batch=[1143], ptr=[65])\n",
      "\n",
      "Step 48:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2440], edge_attr=[2440], batch=[1181], ptr=[65])\n",
      "\n",
      "Step 49:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2278], edge_attr=[2278], batch=[1108], ptr=[65])\n",
      "\n",
      "Step 50:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2172], edge_attr=[2172], batch=[1058], ptr=[65])\n",
      "\n",
      "Step 51:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2150], edge_attr=[2150], batch=[1051], ptr=[65])\n",
      "\n",
      "Step 52:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2232], edge_attr=[2232], batch=[1103], ptr=[65])\n",
      "\n",
      "Step 53:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2166], edge_attr=[2166], batch=[1063], ptr=[65])\n",
      "\n",
      "Step 54:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2256], edge_attr=[2256], batch=[1120], ptr=[65])\n",
      "\n",
      "Step 55:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2090], edge_attr=[2090], batch=[1031], ptr=[65])\n",
      "\n",
      "Step 56:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 1986], edge_attr=[1986], batch=[984], ptr=[65])\n",
      "\n",
      "Step 57:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2024], edge_attr=[2024], batch=[994], ptr=[65])\n",
      "\n",
      "Step 58:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2018], edge_attr=[2018], batch=[1004], ptr=[65])\n",
      "\n",
      "Step 59:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2316], edge_attr=[2316], batch=[1109], ptr=[65])\n",
      "\n",
      "Step 60:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2330], edge_attr=[2330], batch=[1150], ptr=[65])\n",
      "\n",
      "Step 61:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2178], edge_attr=[2178], batch=[1055], ptr=[65])\n",
      "\n",
      "Step 62:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2314], edge_attr=[2314], batch=[1130], ptr=[65])\n",
      "\n",
      "Step 63:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2166], edge_attr=[2166], batch=[1062], ptr=[65])\n",
      "\n",
      "Step 64:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2180], edge_attr=[2180], batch=[1078], ptr=[65])\n",
      "\n",
      "Step 65:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 1982], edge_attr=[1982], batch=[974], ptr=[65])\n",
      "\n",
      "Step 66:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2324], edge_attr=[2324], batch=[1135], ptr=[65])\n",
      "\n",
      "Step 67:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2254], edge_attr=[2254], batch=[1098], ptr=[65])\n",
      "\n",
      "Step 68:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2462], edge_attr=[2462], batch=[1200], ptr=[65])\n",
      "\n",
      "Step 69:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2056], edge_attr=[2056], batch=[1017], ptr=[65])\n",
      "\n",
      "Step 70:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2126], edge_attr=[2126], batch=[1050], ptr=[65])\n",
      "\n",
      "Step 71:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2164], edge_attr=[2164], batch=[1061], ptr=[65])\n",
      "\n",
      "Step 72:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2258], edge_attr=[2258], batch=[1107], ptr=[65])\n",
      "\n",
      "Step 73:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2330], edge_attr=[2330], batch=[1144], ptr=[65])\n",
      "\n",
      "Step 74:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 1992], edge_attr=[1992], batch=[977], ptr=[65])\n",
      "\n",
      "Step 75:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2098], edge_attr=[2098], batch=[1043], ptr=[65])\n",
      "\n",
      "Step 76:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2052], edge_attr=[2052], batch=[1018], ptr=[65])\n",
      "\n",
      "Step 77:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2218], edge_attr=[2218], batch=[1077], ptr=[65])\n",
      "\n",
      "Step 78:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2070], edge_attr=[2070], batch=[1016], ptr=[65])\n",
      "\n",
      "Step 79:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 1986], edge_attr=[1986], batch=[974], ptr=[65])\n",
      "\n",
      "Step 80:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2366], edge_attr=[2366], batch=[1162], ptr=[65])\n",
      "\n",
      "Step 81:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2388], edge_attr=[2388], batch=[1169], ptr=[65])\n",
      "\n",
      "Step 82:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2132], edge_attr=[2132], batch=[1041], ptr=[65])\n",
      "\n",
      "Step 83:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2242], edge_attr=[2242], batch=[1102], ptr=[65])\n",
      "\n",
      "Step 84:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2034], edge_attr=[2034], batch=[996], ptr=[65])\n",
      "\n",
      "Step 85:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2052], edge_attr=[2052], batch=[1003], ptr=[65])\n",
      "\n",
      "Step 86:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2280], edge_attr=[2280], batch=[1116], ptr=[65])\n",
      "\n",
      "Step 87:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2168], edge_attr=[2168], batch=[1066], ptr=[65])\n",
      "\n",
      "Step 88:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2548], edge_attr=[2548], batch=[1238], ptr=[65])\n",
      "\n",
      "Step 89:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 1990], edge_attr=[1990], batch=[999], ptr=[65])\n",
      "\n",
      "Step 90:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2144], edge_attr=[2144], batch=[1051], ptr=[65])\n",
      "\n",
      "Step 91:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 1992], edge_attr=[1992], batch=[979], ptr=[65])\n",
      "\n",
      "Step 92:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2274], edge_attr=[2274], batch=[1110], ptr=[65])\n",
      "\n",
      "Step 93:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2024], edge_attr=[2024], batch=[983], ptr=[65])\n",
      "\n",
      "Step 94:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2262], edge_attr=[2262], batch=[1100], ptr=[65])\n",
      "\n",
      "Step 95:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2006], edge_attr=[2006], batch=[981], ptr=[65])\n",
      "\n",
      "Step 96:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2224], edge_attr=[2224], batch=[1080], ptr=[65])\n",
      "\n",
      "Step 97:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2294], edge_attr=[2294], batch=[1107], ptr=[65])\n",
      "\n",
      "Step 98:\n",
      "=======\n",
      "Number of graphs in the current batch: 56\n",
      "DataBatch(x=[56], edge_index=[2, 1860], edge_attr=[1860], batch=[904], ptr=[57])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step, data in enumerate(train_loader):\n",
    "    print(f'Step {step + 1}:')\n",
    "    print('=======')\n",
    "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "    print(data)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm. Slight issue with the x parameter, but no clear solution is popping out to me at the moment. As my friend Dan likes to say, \"Let's circle back to this.\"\n",
    "\n",
    "Also, small (*very* consequential) update: after spending 2 days trying to get perfectly preprocess this data, I have discovered that PyTorch Geometric supplies its own MoleculeNet class, complete with a Tox 21 dataset ðŸ¥².\n",
    "\n",
    "Despite how much my RAM has suffered due to tabs upon tabs of documentation, I'd say that this process helped clarify **how** and **why** we preprocess our data. Now let's condense yesterday's work into three lines!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihirarya/Dev/bcil/tox21/env/lib/python3.10/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[145459, 9], edge_index=[2, 302190], edge_attr=[302190, 3], smiles=[7831], y=[7831, 12])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.datasets import MoleculeNet\n",
    "dataset = MoleculeNet(root=\"./data/\", name=\"Tox21\")\n",
    "dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: Tox21(7831):\n",
      "====================\n",
      "Number of graphs: 7831\n",
      "Number of features: 9\n",
      "Number of classes: 12\n",
      "\n",
      "Data(x=[16, 9], edge_index=[2, 34], edge_attr=[34, 3], smiles='CCOc1ccc2nc(S(N)(=O)=O)sc2c1', y=[1, 12])\n",
      "=============================================================\n",
      "Number of nodes: 16\n",
      "Number of edges: 34\n",
      "Average node degree: 2.12\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print('=============================================================')\n",
    "\n",
    "# Gather some statistics about the first graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 12 targets to predict, which is 11 too many to do at once - let's select NR-AhR (column 3) as the target to predict. Some of the rows in our dataset have a `NaN` value for this task, so we must them filter out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1., nan, nan, 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some datatype manipulation so we don't run into issues downstream!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.y = dataset.y.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shuffle()\n",
    "column_index_to_check = 2\n",
    "filtered_data_list = [data for data in dataset if not torch.isnan(data.y[0, column_index_to_check]).any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 5239\n",
      "Number of test graphs: 1310\n"
     ]
    }
   ],
   "source": [
    "split = int(len(filtered_data_list) * 0.80)\n",
    "train_dataset, test_dataset = filtered_data_list[:split], filtered_data_list[split:]\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're cooking with this dataset: shuffled, filtered, and split. We can finally move on..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step: **Mini-batching**.\n",
    "\n",
    "Instead of \"stacking\" equally-sized matrices into a single mini-batch, as we may have done with image data, we take an alternative approach with graph data. \"Why overcomplicate things?\" you may ask. According to PyTorch Geometric [documentation](https://colab.research.google.com/drive/1I8a0DfQ3fI7Njc62__mVXUlcAleUclnb?usp=sharing#scrollTo=0gZ-l0npPIca):\n",
    "\n",
    "1. GNN operators that rely on a **message passing scheme** (more on this later) do not need to be modified since messages are not exchanged between two nodes that belong to different graphs\n",
    "\n",
    "2. There is no computational or memory overhead since adjacency matrices are saved in a sparse fashion holding only non-zero entries (*i.e.*, the edges)\n",
    "\n",
    "PyTorch Geometric automatically takes care of **batching multiple graphs into a single giant graph** with the help of the [`torch_geometric.data.DataLoader`](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.DataLoader) class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1284, 9], edge_index=[2, 2656], edge_attr=[2656, 3], smiles=[64], y=[64, 12], batch=[1284], ptr=[65])\n",
      "\n",
      "Step 2:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1139, 9], edge_index=[2, 2374], edge_attr=[2374, 3], smiles=[64], y=[64, 12], batch=[1139], ptr=[65])\n",
      "\n",
      "Step 3:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1266, 9], edge_index=[2, 2584], edge_attr=[2584, 3], smiles=[64], y=[64, 12], batch=[1266], ptr=[65])\n",
      "\n",
      "Step 4:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1130, 9], edge_index=[2, 2330], edge_attr=[2330, 3], smiles=[64], y=[64, 12], batch=[1130], ptr=[65])\n",
      "\n",
      "Step 5:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1109, 9], edge_index=[2, 2264], edge_attr=[2264, 3], smiles=[64], y=[64, 12], batch=[1109], ptr=[65])\n",
      "\n",
      "Step 6:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1095, 9], edge_index=[2, 2272], edge_attr=[2272, 3], smiles=[64], y=[64, 12], batch=[1095], ptr=[65])\n",
      "\n",
      "Step 7:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1062, 9], edge_index=[2, 2194], edge_attr=[2194, 3], smiles=[64], y=[64, 12], batch=[1062], ptr=[65])\n",
      "\n",
      "Step 8:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1117, 9], edge_index=[2, 2348], edge_attr=[2348, 3], smiles=[64], y=[64, 12], batch=[1117], ptr=[65])\n",
      "\n",
      "Step 9:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1057, 9], edge_index=[2, 2178], edge_attr=[2178, 3], smiles=[64], y=[64, 12], batch=[1057], ptr=[65])\n",
      "\n",
      "Step 10:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1247, 9], edge_index=[2, 2564], edge_attr=[2564, 3], smiles=[64], y=[64, 12], batch=[1247], ptr=[65])\n",
      "\n",
      "Step 11:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1095, 9], edge_index=[2, 2292], edge_attr=[2292, 3], smiles=[64], y=[64, 12], batch=[1095], ptr=[65])\n",
      "\n",
      "Step 12:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1207, 9], edge_index=[2, 2496], edge_attr=[2496, 3], smiles=[64], y=[64, 12], batch=[1207], ptr=[65])\n",
      "\n",
      "Step 13:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1082, 9], edge_index=[2, 2216], edge_attr=[2216, 3], smiles=[64], y=[64, 12], batch=[1082], ptr=[65])\n",
      "\n",
      "Step 14:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1030, 9], edge_index=[2, 2130], edge_attr=[2130, 3], smiles=[64], y=[64, 12], batch=[1030], ptr=[65])\n",
      "\n",
      "Step 15:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1082, 9], edge_index=[2, 2244], edge_attr=[2244, 3], smiles=[64], y=[64, 12], batch=[1082], ptr=[65])\n",
      "\n",
      "Step 16:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1212, 9], edge_index=[2, 2520], edge_attr=[2520, 3], smiles=[64], y=[64, 12], batch=[1212], ptr=[65])\n",
      "\n",
      "Step 17:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1148, 9], edge_index=[2, 2384], edge_attr=[2384, 3], smiles=[64], y=[64, 12], batch=[1148], ptr=[65])\n",
      "\n",
      "Step 18:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1152, 9], edge_index=[2, 2396], edge_attr=[2396, 3], smiles=[64], y=[64, 12], batch=[1152], ptr=[65])\n",
      "\n",
      "Step 19:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1184, 9], edge_index=[2, 2462], edge_attr=[2462, 3], smiles=[64], y=[64, 12], batch=[1184], ptr=[65])\n",
      "\n",
      "Step 20:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1439, 9], edge_index=[2, 3014], edge_attr=[3014, 3], smiles=[64], y=[64, 12], batch=[1439], ptr=[65])\n",
      "\n",
      "Step 21:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1098, 9], edge_index=[2, 2288], edge_attr=[2288, 3], smiles=[64], y=[64, 12], batch=[1098], ptr=[65])\n",
      "\n",
      "Step 22:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1186, 9], edge_index=[2, 2464], edge_attr=[2464, 3], smiles=[64], y=[64, 12], batch=[1186], ptr=[65])\n",
      "\n",
      "Step 23:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1118, 9], edge_index=[2, 2332], edge_attr=[2332, 3], smiles=[64], y=[64, 12], batch=[1118], ptr=[65])\n",
      "\n",
      "Step 24:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1206, 9], edge_index=[2, 2516], edge_attr=[2516, 3], smiles=[64], y=[64, 12], batch=[1206], ptr=[65])\n",
      "\n",
      "Step 25:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1266, 9], edge_index=[2, 2602], edge_attr=[2602, 3], smiles=[64], y=[64, 12], batch=[1266], ptr=[65])\n",
      "\n",
      "Step 26:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1062, 9], edge_index=[2, 2190], edge_attr=[2190, 3], smiles=[64], y=[64, 12], batch=[1062], ptr=[65])\n",
      "\n",
      "Step 27:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1326, 9], edge_index=[2, 2768], edge_attr=[2768, 3], smiles=[64], y=[64, 12], batch=[1326], ptr=[65])\n",
      "\n",
      "Step 28:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1096, 9], edge_index=[2, 2280], edge_attr=[2280, 3], smiles=[64], y=[64, 12], batch=[1096], ptr=[65])\n",
      "\n",
      "Step 29:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1178, 9], edge_index=[2, 2412], edge_attr=[2412, 3], smiles=[64], y=[64, 12], batch=[1178], ptr=[65])\n",
      "\n",
      "Step 30:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1072, 9], edge_index=[2, 2234], edge_attr=[2234, 3], smiles=[64], y=[64, 12], batch=[1072], ptr=[65])\n",
      "\n",
      "Step 31:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1122, 9], edge_index=[2, 2322], edge_attr=[2322, 3], smiles=[64], y=[64, 12], batch=[1122], ptr=[65])\n",
      "\n",
      "Step 32:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1253, 9], edge_index=[2, 2598], edge_attr=[2598, 3], smiles=[64], y=[64, 12], batch=[1253], ptr=[65])\n",
      "\n",
      "Step 33:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1129, 9], edge_index=[2, 2336], edge_attr=[2336, 3], smiles=[64], y=[64, 12], batch=[1129], ptr=[65])\n",
      "\n",
      "Step 34:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1173, 9], edge_index=[2, 2436], edge_attr=[2436, 3], smiles=[64], y=[64, 12], batch=[1173], ptr=[65])\n",
      "\n",
      "Step 35:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1069, 9], edge_index=[2, 2184], edge_attr=[2184, 3], smiles=[64], y=[64, 12], batch=[1069], ptr=[65])\n",
      "\n",
      "Step 36:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1081, 9], edge_index=[2, 2228], edge_attr=[2228, 3], smiles=[64], y=[64, 12], batch=[1081], ptr=[65])\n",
      "\n",
      "Step 37:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1023, 9], edge_index=[2, 2096], edge_attr=[2096, 3], smiles=[64], y=[64, 12], batch=[1023], ptr=[65])\n",
      "\n",
      "Step 38:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1271, 9], edge_index=[2, 2654], edge_attr=[2654, 3], smiles=[64], y=[64, 12], batch=[1271], ptr=[65])\n",
      "\n",
      "Step 39:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1188, 9], edge_index=[2, 2476], edge_attr=[2476, 3], smiles=[64], y=[64, 12], batch=[1188], ptr=[65])\n",
      "\n",
      "Step 40:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1339, 9], edge_index=[2, 2812], edge_attr=[2812, 3], smiles=[64], y=[64, 12], batch=[1339], ptr=[65])\n",
      "\n",
      "Step 41:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1185, 9], edge_index=[2, 2452], edge_attr=[2452, 3], smiles=[64], y=[64, 12], batch=[1185], ptr=[65])\n",
      "\n",
      "Step 42:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1063, 9], edge_index=[2, 2202], edge_attr=[2202, 3], smiles=[64], y=[64, 12], batch=[1063], ptr=[65])\n",
      "\n",
      "Step 43:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1193, 9], edge_index=[2, 2472], edge_attr=[2472, 3], smiles=[64], y=[64, 12], batch=[1193], ptr=[65])\n",
      "\n",
      "Step 44:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1129, 9], edge_index=[2, 2330], edge_attr=[2330, 3], smiles=[64], y=[64, 12], batch=[1129], ptr=[65])\n",
      "\n",
      "Step 45:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1017, 9], edge_index=[2, 2072], edge_attr=[2072, 3], smiles=[64], y=[64, 12], batch=[1017], ptr=[65])\n",
      "\n",
      "Step 46:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1071, 9], edge_index=[2, 2208], edge_attr=[2208, 3], smiles=[64], y=[64, 12], batch=[1071], ptr=[65])\n",
      "\n",
      "Step 47:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1297, 9], edge_index=[2, 2700], edge_attr=[2700, 3], smiles=[64], y=[64, 12], batch=[1297], ptr=[65])\n",
      "\n",
      "Step 48:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1212, 9], edge_index=[2, 2516], edge_attr=[2516, 3], smiles=[64], y=[64, 12], batch=[1212], ptr=[65])\n",
      "\n",
      "Step 49:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1305, 9], edge_index=[2, 2716], edge_attr=[2716, 3], smiles=[64], y=[64, 12], batch=[1305], ptr=[65])\n",
      "\n",
      "Step 50:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1206, 9], edge_index=[2, 2496], edge_attr=[2496, 3], smiles=[64], y=[64, 12], batch=[1206], ptr=[65])\n",
      "\n",
      "Step 51:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1083, 9], edge_index=[2, 2256], edge_attr=[2256, 3], smiles=[64], y=[64, 12], batch=[1083], ptr=[65])\n",
      "\n",
      "Step 52:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1048, 9], edge_index=[2, 2154], edge_attr=[2154, 3], smiles=[64], y=[64, 12], batch=[1048], ptr=[65])\n",
      "\n",
      "Step 53:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1166, 9], edge_index=[2, 2416], edge_attr=[2416, 3], smiles=[64], y=[64, 12], batch=[1166], ptr=[65])\n",
      "\n",
      "Step 54:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1124, 9], edge_index=[2, 2306], edge_attr=[2306, 3], smiles=[64], y=[64, 12], batch=[1124], ptr=[65])\n",
      "\n",
      "Step 55:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1257, 9], edge_index=[2, 2608], edge_attr=[2608, 3], smiles=[64], y=[64, 12], batch=[1257], ptr=[65])\n",
      "\n",
      "Step 56:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1138, 9], edge_index=[2, 2384], edge_attr=[2384, 3], smiles=[64], y=[64, 12], batch=[1138], ptr=[65])\n",
      "\n",
      "Step 57:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1131, 9], edge_index=[2, 2376], edge_attr=[2376, 3], smiles=[64], y=[64, 12], batch=[1131], ptr=[65])\n",
      "\n",
      "Step 58:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1155, 9], edge_index=[2, 2352], edge_attr=[2352, 3], smiles=[64], y=[64, 12], batch=[1155], ptr=[65])\n",
      "\n",
      "Step 59:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1030, 9], edge_index=[2, 2102], edge_attr=[2102, 3], smiles=[64], y=[64, 12], batch=[1030], ptr=[65])\n",
      "\n",
      "Step 60:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1199, 9], edge_index=[2, 2502], edge_attr=[2502, 3], smiles=[64], y=[64, 12], batch=[1199], ptr=[65])\n",
      "\n",
      "Step 61:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1217, 9], edge_index=[2, 2532], edge_attr=[2532, 3], smiles=[64], y=[64, 12], batch=[1217], ptr=[65])\n",
      "\n",
      "Step 62:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1070, 9], edge_index=[2, 2182], edge_attr=[2182, 3], smiles=[64], y=[64, 12], batch=[1070], ptr=[65])\n",
      "\n",
      "Step 63:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1220, 9], edge_index=[2, 2564], edge_attr=[2564, 3], smiles=[64], y=[64, 12], batch=[1220], ptr=[65])\n",
      "\n",
      "Step 64:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1193, 9], edge_index=[2, 2480], edge_attr=[2480, 3], smiles=[64], y=[64, 12], batch=[1193], ptr=[65])\n",
      "\n",
      "Step 65:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1215, 9], edge_index=[2, 2536], edge_attr=[2536, 3], smiles=[64], y=[64, 12], batch=[1215], ptr=[65])\n",
      "\n",
      "Step 66:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1225, 9], edge_index=[2, 2548], edge_attr=[2548, 3], smiles=[64], y=[64, 12], batch=[1225], ptr=[65])\n",
      "\n",
      "Step 67:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1148, 9], edge_index=[2, 2386], edge_attr=[2386, 3], smiles=[64], y=[64, 12], batch=[1148], ptr=[65])\n",
      "\n",
      "Step 68:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1039, 9], edge_index=[2, 2108], edge_attr=[2108, 3], smiles=[64], y=[64, 12], batch=[1039], ptr=[65])\n",
      "\n",
      "Step 69:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1115, 9], edge_index=[2, 2302], edge_attr=[2302, 3], smiles=[64], y=[64, 12], batch=[1115], ptr=[65])\n",
      "\n",
      "Step 70:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1164, 9], edge_index=[2, 2430], edge_attr=[2430, 3], smiles=[64], y=[64, 12], batch=[1164], ptr=[65])\n",
      "\n",
      "Step 71:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1028, 9], edge_index=[2, 2098], edge_attr=[2098, 3], smiles=[64], y=[64, 12], batch=[1028], ptr=[65])\n",
      "\n",
      "Step 72:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1199, 9], edge_index=[2, 2502], edge_attr=[2502, 3], smiles=[64], y=[64, 12], batch=[1199], ptr=[65])\n",
      "\n",
      "Step 73:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1158, 9], edge_index=[2, 2432], edge_attr=[2432, 3], smiles=[64], y=[64, 12], batch=[1158], ptr=[65])\n",
      "\n",
      "Step 74:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1227, 9], edge_index=[2, 2532], edge_attr=[2532, 3], smiles=[64], y=[64, 12], batch=[1227], ptr=[65])\n",
      "\n",
      "Step 75:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1177, 9], edge_index=[2, 2474], edge_attr=[2474, 3], smiles=[64], y=[64, 12], batch=[1177], ptr=[65])\n",
      "\n",
      "Step 76:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1196, 9], edge_index=[2, 2426], edge_attr=[2426, 3], smiles=[64], y=[64, 12], batch=[1196], ptr=[65])\n",
      "\n",
      "Step 77:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1072, 9], edge_index=[2, 2212], edge_attr=[2212, 3], smiles=[64], y=[64, 12], batch=[1072], ptr=[65])\n",
      "\n",
      "Step 78:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1005, 9], edge_index=[2, 2064], edge_attr=[2064, 3], smiles=[64], y=[64, 12], batch=[1005], ptr=[65])\n",
      "\n",
      "Step 79:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1061, 9], edge_index=[2, 2176], edge_attr=[2176, 3], smiles=[64], y=[64, 12], batch=[1061], ptr=[65])\n",
      "\n",
      "Step 80:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1179, 9], edge_index=[2, 2466], edge_attr=[2466, 3], smiles=[64], y=[64, 12], batch=[1179], ptr=[65])\n",
      "\n",
      "Step 81:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1225, 9], edge_index=[2, 2518], edge_attr=[2518, 3], smiles=[64], y=[64, 12], batch=[1225], ptr=[65])\n",
      "\n",
      "Step 82:\n",
      "=======\n",
      "Number of graphs in the current batch: 55\n",
      "DataBatch(x=[1012, 9], edge_index=[2, 2064], edge_attr=[2064, 3], smiles=[55], y=[55, 12], batch=[1012], ptr=[56])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "for step, data in enumerate(train_loader):\n",
    "    print(f'Step {step + 1}:')\n",
    "    print('=======')\n",
    "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "    print(data)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mini-batch data âœ…\n",
    "\n",
    "Next step: Graph. Neural. Networks.\n",
    "\n",
    "FINALLY. Let's make like Merriam-Webster and define what our GNN is going to look like.\n",
    "\n",
    "But before we that, let's quickly review message-passing (you're welcome, future me)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!TODO: EXPLAIN MESSAGE PASSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the main course: defining the model. Thank you to the wonderful people at [PyTorch](https://www.learnpytorch.io/02_pytorch_classification/) and [PyTorch Geometric](https://colab.research.google.com/drive/1I8a0DfQ3fI7Njc62__mVXUlcAleUclnb?usp=sharing#scrollTo=mHSP6-RBOqCE) for these thoroughly-documented references (they low-key carried). Take a look at them if you haven't already!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN(\n",
      "  (conv1): GraphConv(9, 64)\n",
      "  (conv2): GraphConv(64, 64)\n",
      "  (conv3): GraphConv(64, 64)\n",
      "  (lin): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GraphConv\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GNN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GraphConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2 = GraphConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GraphConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, 1) # Output a binary value (0 or 1) because this is a binary classification problem \n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        x = x.to(self.lin.weight.dtype)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = GNN(hidden_channels=64)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Graph Neural Network for graph classification âœ…\n",
    "\n",
    "\n",
    "And finally, the code that we'll use to train and test our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal\n",
    "    acc = (correct / len(y_pred)) * 100 \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "def train(loader):\n",
    "    model.train()\n",
    "\n",
    "    train_loss, train_acc = 0, 0\n",
    "    for data in loader:  # Iterate in batches over the training dataset.\n",
    "         \n",
    "         # 1. Forward pass (model outputs raw logits)\n",
    "         y_logits = model(data.x.to(torch.float32), data.edge_index, data.batch)\n",
    "         y_preds = torch.round(torch.sigmoid(y_logits))\n",
    "         y_train = data.y[:, column_index_to_check] # extract target column\n",
    "         \n",
    "         # 2. Calculate loss/accuracy\n",
    "         loss = loss_fn(y_logits.squeeze(), y_train)\n",
    "         train_loss += loss\n",
    "         train_acc += accuracy_fn(y_true=y_train, y_pred=y_preds.squeeze())\n",
    "\n",
    "         # 3. Optimizer zero grad\n",
    "         optimizer.zero_grad() \n",
    "\n",
    "         # 4. Loss backwards\n",
    "         loss.backward()  \n",
    "\n",
    "         # 5. Optimizer step\n",
    "         optimizer.step()\n",
    "    train_loss /= len(loader)\n",
    "    train_acc /= len(loader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "def test(loader):\n",
    "     model.eval()\n",
    "\n",
    "     test_loss, test_acc = 0, 0\n",
    "     for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "         test_logits = model(data.x.to(torch.float32), data.edge_index, data.batch)\n",
    "         test_preds = torch.round(torch.sigmoid(test_logits))\n",
    "         labels = data.y[:, column_index_to_check] # extract target column\n",
    "\n",
    "         test_loss += loss_fn(test_logits.squeeze(), labels)\n",
    "         test_acc += accuracy_fn(y_true=labels, y_pred=test_preds.squeeze())\n",
    "     test_loss /= len(loader)\n",
    "     test_acc /= len(loader)\n",
    "     print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.46709 | Train accuracy: 86.55%\n",
      "Test loss: 0.30009 | Test accuracy: 88.61%\n",
      "\n",
      "Train loss: 0.32101 | Train accuracy: 88.04%\n",
      "Test loss: 0.29506 | Test accuracy: 88.61%\n",
      "\n",
      "Train loss: 0.30924 | Train accuracy: 88.25%\n",
      "Test loss: 0.31156 | Test accuracy: 88.61%\n",
      "\n",
      "Train loss: 0.30842 | Train accuracy: 88.24%\n",
      "Test loss: 0.29471 | Test accuracy: 88.61%\n",
      "\n",
      "Train loss: 0.30941 | Train accuracy: 88.25%\n",
      "Test loss: 0.29283 | Test accuracy: 88.61%\n",
      "\n",
      "Train loss: 0.30037 | Train accuracy: 88.25%\n",
      "Test loss: 0.28817 | Test accuracy: 88.61%\n",
      "\n",
      "Train loss: 0.30182 | Train accuracy: 88.24%\n",
      "Test loss: 0.29172 | Test accuracy: 88.61%\n",
      "\n",
      "Train loss: 0.30725 | Train accuracy: 88.24%\n",
      "Test loss: 0.28652 | Test accuracy: 88.61%\n",
      "\n",
      "Train loss: 0.29302 | Train accuracy: 88.34%\n",
      "Test loss: 0.28141 | Test accuracy: 89.28%\n",
      "\n",
      "Train loss: 0.29313 | Train accuracy: 88.46%\n",
      "Test loss: 0.28418 | Test accuracy: 89.26%\n",
      "\n",
      "Train loss: 0.29138 | Train accuracy: 88.13%\n",
      "Test loss: 0.28410 | Test accuracy: 88.61%\n",
      "\n",
      "Train loss: 0.29365 | Train accuracy: 88.14%\n",
      "Test loss: 0.27985 | Test accuracy: 89.57%\n",
      "\n",
      "Train loss: 0.28542 | Train accuracy: 88.39%\n",
      "Test loss: 0.29385 | Test accuracy: 88.61%\n",
      "\n",
      "Train loss: 0.28814 | Train accuracy: 88.47%\n",
      "Test loss: 0.28579 | Test accuracy: 88.75%\n",
      "\n",
      "Train loss: 0.29431 | Train accuracy: 88.16%\n",
      "Test loss: 0.28014 | Test accuracy: 88.61%\n",
      "\n",
      "Train loss: 0.29337 | Train accuracy: 88.31%\n",
      "Test loss: 0.28316 | Test accuracy: 88.90%\n",
      "\n",
      "Train loss: 0.28476 | Train accuracy: 88.33%\n",
      "Test loss: 0.27442 | Test accuracy: 88.90%\n",
      "\n",
      "Train loss: 0.28628 | Train accuracy: 88.66%\n",
      "Test loss: 0.27424 | Test accuracy: 88.90%\n",
      "\n",
      "Train loss: 0.28955 | Train accuracy: 88.57%\n",
      "Test loss: 0.26551 | Test accuracy: 89.20%\n",
      "\n",
      "Train loss: 0.28256 | Train accuracy: 88.53%\n",
      "Test loss: 0.27328 | Test accuracy: 89.20%\n",
      "\n",
      "Train loss: 0.28081 | Train accuracy: 88.73%\n",
      "Test loss: 0.28542 | Test accuracy: 88.83%\n",
      "\n",
      "Train loss: 0.28357 | Train accuracy: 88.18%\n",
      "Test loss: 0.27393 | Test accuracy: 88.61%\n",
      "\n",
      "Train loss: 0.28436 | Train accuracy: 88.53%\n",
      "Test loss: 0.27294 | Test accuracy: 89.57%\n",
      "\n",
      "Train loss: 0.28507 | Train accuracy: 88.78%\n",
      "Test loss: 0.31944 | Test accuracy: 88.34%\n",
      "\n",
      "Train loss: 0.29816 | Train accuracy: 88.32%\n",
      "Test loss: 0.30190 | Test accuracy: 88.61%\n",
      "\n",
      "Train loss: 0.27892 | Train accuracy: 88.55%\n",
      "Test loss: 0.29413 | Test accuracy: 89.80%\n",
      "\n",
      "Train loss: 0.27929 | Train accuracy: 88.69%\n",
      "Test loss: 0.26694 | Test accuracy: 89.57%\n",
      "\n",
      "Train loss: 0.27746 | Train accuracy: 88.82%\n",
      "Test loss: 0.27373 | Test accuracy: 90.23%\n",
      "\n",
      "Train loss: 0.28101 | Train accuracy: 88.38%\n",
      "Test loss: 0.26796 | Test accuracy: 89.87%\n",
      "\n",
      "Train loss: 0.27827 | Train accuracy: 88.87%\n",
      "Test loss: 0.26674 | Test accuracy: 89.42%\n",
      "\n",
      "Train loss: 0.28963 | Train accuracy: 88.47%\n",
      "Test loss: 0.26934 | Test accuracy: 89.80%\n",
      "\n",
      "Train loss: 0.28173 | Train accuracy: 88.82%\n",
      "Test loss: 0.27876 | Test accuracy: 89.33%\n",
      "\n",
      "Train loss: 0.27777 | Train accuracy: 88.84%\n",
      "Test loss: 0.25772 | Test accuracy: 89.95%\n",
      "\n",
      "Train loss: 0.27536 | Train accuracy: 88.82%\n",
      "Test loss: 0.27152 | Test accuracy: 88.83%\n",
      "\n",
      "Train loss: 0.27757 | Train accuracy: 89.02%\n",
      "Test loss: 0.26418 | Test accuracy: 90.17%\n",
      "\n",
      "Train loss: 0.27145 | Train accuracy: 89.04%\n",
      "Test loss: 0.27573 | Test accuracy: 89.20%\n",
      "\n",
      "Train loss: 0.28028 | Train accuracy: 88.79%\n",
      "Test loss: 0.27125 | Test accuracy: 89.50%\n",
      "\n",
      "Train loss: 0.27065 | Train accuracy: 88.79%\n",
      "Test loss: 0.27789 | Test accuracy: 90.09%\n",
      "\n",
      "Train loss: 0.27477 | Train accuracy: 88.95%\n",
      "Test loss: 0.26854 | Test accuracy: 90.39%\n",
      "\n",
      "Train loss: 0.27238 | Train accuracy: 89.12%\n",
      "Test loss: 0.29529 | Test accuracy: 88.88%\n",
      "\n",
      "Train loss: 0.27191 | Train accuracy: 88.92%\n",
      "Test loss: 0.26758 | Test accuracy: 90.24%\n",
      "\n",
      "Train loss: 0.27508 | Train accuracy: 88.95%\n",
      "Test loss: 0.27113 | Test accuracy: 90.39%\n",
      "\n",
      "Train loss: 0.26888 | Train accuracy: 89.24%\n",
      "Test loss: 0.26417 | Test accuracy: 90.09%\n",
      "\n",
      "Train loss: 0.26999 | Train accuracy: 88.85%\n",
      "Test loss: 0.26199 | Test accuracy: 89.65%\n",
      "\n",
      "Train loss: 0.27061 | Train accuracy: 88.68%\n",
      "Test loss: 0.27786 | Test accuracy: 90.09%\n",
      "\n",
      "Train loss: 0.27112 | Train accuracy: 88.84%\n",
      "Test loss: 0.26477 | Test accuracy: 90.54%\n",
      "\n",
      "Train loss: 0.26435 | Train accuracy: 88.91%\n",
      "Test loss: 0.26815 | Test accuracy: 89.87%\n",
      "\n",
      "Train loss: 0.27173 | Train accuracy: 88.86%\n",
      "Test loss: 0.26941 | Test accuracy: 90.24%\n",
      "\n",
      "Train loss: 0.27647 | Train accuracy: 89.29%\n",
      "Test loss: 0.26146 | Test accuracy: 89.95%\n",
      "\n",
      "Train loss: 0.26515 | Train accuracy: 89.39%\n",
      "Test loss: 0.27926 | Test accuracy: 88.90%\n",
      "\n",
      "Train loss: 0.27248 | Train accuracy: 88.88%\n",
      "Test loss: 0.27278 | Test accuracy: 89.35%\n",
      "\n",
      "Train loss: 0.26824 | Train accuracy: 89.05%\n",
      "Test loss: 0.26793 | Test accuracy: 89.05%\n",
      "\n",
      "Train loss: 0.27553 | Train accuracy: 88.65%\n",
      "Test loss: 0.26629 | Test accuracy: 89.80%\n",
      "\n",
      "Train loss: 0.27759 | Train accuracy: 88.78%\n",
      "Test loss: 0.27020 | Test accuracy: 89.65%\n",
      "\n",
      "Train loss: 0.27225 | Train accuracy: 88.86%\n",
      "Test loss: 0.26552 | Test accuracy: 89.57%\n",
      "\n",
      "Train loss: 0.27219 | Train accuracy: 88.90%\n",
      "Test loss: 0.28975 | Test accuracy: 88.68%\n",
      "\n",
      "Train loss: 0.26829 | Train accuracy: 89.26%\n",
      "Test loss: 0.26680 | Test accuracy: 89.80%\n",
      "\n",
      "Train loss: 0.27208 | Train accuracy: 88.88%\n",
      "Test loss: 0.26531 | Test accuracy: 90.02%\n",
      "\n",
      "Train loss: 0.26821 | Train accuracy: 89.02%\n",
      "Test loss: 0.27403 | Test accuracy: 88.98%\n",
      "\n",
      "Train loss: 0.26541 | Train accuracy: 89.14%\n",
      "Test loss: 0.26731 | Test accuracy: 90.02%\n",
      "\n",
      "Train loss: 0.26494 | Train accuracy: 89.05%\n",
      "Test loss: 0.26445 | Test accuracy: 90.24%\n",
      "\n",
      "Train loss: 0.26416 | Train accuracy: 89.06%\n",
      "Test loss: 0.26744 | Test accuracy: 90.02%\n",
      "\n",
      "Train loss: 0.27232 | Train accuracy: 88.68%\n",
      "Test loss: 0.28596 | Test accuracy: 88.75%\n",
      "\n",
      "Train loss: 0.27294 | Train accuracy: 89.31%\n",
      "Test loss: 0.28264 | Test accuracy: 88.68%\n",
      "\n",
      "Train loss: 0.26360 | Train accuracy: 89.33%\n",
      "Test loss: 0.26412 | Test accuracy: 90.17%\n",
      "\n",
      "Train loss: 0.26035 | Train accuracy: 89.44%\n",
      "Test loss: 0.26436 | Test accuracy: 90.24%\n",
      "\n",
      "Train loss: 0.26475 | Train accuracy: 89.21%\n",
      "Test loss: 0.27027 | Test accuracy: 89.72%\n",
      "\n",
      "Train loss: 0.25999 | Train accuracy: 89.19%\n",
      "Test loss: 0.26555 | Test accuracy: 90.17%\n",
      "\n",
      "Train loss: 0.26857 | Train accuracy: 88.86%\n",
      "Test loss: 0.26577 | Test accuracy: 89.87%\n",
      "\n",
      "Train loss: 0.26045 | Train accuracy: 89.47%\n",
      "Test loss: 0.26726 | Test accuracy: 89.65%\n",
      "\n",
      "Train loss: 0.26724 | Train accuracy: 89.11%\n",
      "Test loss: 0.30283 | Test accuracy: 89.05%\n",
      "\n",
      "Train loss: 0.26502 | Train accuracy: 89.56%\n",
      "Test loss: 0.27504 | Test accuracy: 90.09%\n",
      "\n",
      "Train loss: 0.26136 | Train accuracy: 89.22%\n",
      "Test loss: 0.25707 | Test accuracy: 89.20%\n",
      "\n",
      "Train loss: 0.25800 | Train accuracy: 89.34%\n",
      "Test loss: 0.26317 | Test accuracy: 90.24%\n",
      "\n",
      "Train loss: 0.25971 | Train accuracy: 89.40%\n",
      "Test loss: 0.26921 | Test accuracy: 89.50%\n",
      "\n",
      "Train loss: 0.26427 | Train accuracy: 89.22%\n",
      "Test loss: 0.27239 | Test accuracy: 90.39%\n",
      "\n",
      "Train loss: 0.26197 | Train accuracy: 89.50%\n",
      "Test loss: 0.26724 | Test accuracy: 89.87%\n",
      "\n",
      "Train loss: 0.26272 | Train accuracy: 89.13%\n",
      "Test loss: 0.26822 | Test accuracy: 88.98%\n",
      "\n",
      "Train loss: 0.26116 | Train accuracy: 89.23%\n",
      "Test loss: 0.26574 | Test accuracy: 89.72%\n",
      "\n",
      "Train loss: 0.25870 | Train accuracy: 89.47%\n",
      "Test loss: 0.26045 | Test accuracy: 90.09%\n",
      "\n",
      "Train loss: 0.26068 | Train accuracy: 89.41%\n",
      "Test loss: 0.26254 | Test accuracy: 89.13%\n",
      "\n",
      "Train loss: 0.25773 | Train accuracy: 89.31%\n",
      "Test loss: 0.26747 | Test accuracy: 89.87%\n",
      "\n",
      "Train loss: 0.26009 | Train accuracy: 89.31%\n",
      "Test loss: 0.26785 | Test accuracy: 89.80%\n",
      "\n",
      "Train loss: 0.25792 | Train accuracy: 89.07%\n",
      "Test loss: 0.26587 | Test accuracy: 90.09%\n",
      "\n",
      "Train loss: 0.25971 | Train accuracy: 89.19%\n",
      "Test loss: 0.28663 | Test accuracy: 90.01%\n",
      "\n",
      "Train loss: 0.26520 | Train accuracy: 89.06%\n",
      "Test loss: 0.28156 | Test accuracy: 89.28%\n",
      "\n",
      "Train loss: 0.26490 | Train accuracy: 89.29%\n",
      "Test loss: 0.25390 | Test accuracy: 90.39%\n",
      "\n",
      "Train loss: 0.26048 | Train accuracy: 89.15%\n",
      "Test loss: 0.27182 | Test accuracy: 89.80%\n",
      "\n",
      "Train loss: 0.25951 | Train accuracy: 89.41%\n",
      "Test loss: 0.25865 | Test accuracy: 90.17%\n",
      "\n",
      "Train loss: 0.25731 | Train accuracy: 89.49%\n",
      "Test loss: 0.26551 | Test accuracy: 89.95%\n",
      "\n",
      "Train loss: 0.26023 | Train accuracy: 89.07%\n",
      "Test loss: 0.27571 | Test accuracy: 89.13%\n",
      "\n",
      "Train loss: 0.25869 | Train accuracy: 89.24%\n",
      "Test loss: 0.25922 | Test accuracy: 90.24%\n",
      "\n",
      "Train loss: 0.26001 | Train accuracy: 89.14%\n",
      "Test loss: 0.26961 | Test accuracy: 89.35%\n",
      "\n",
      "Train loss: 0.25758 | Train accuracy: 89.43%\n",
      "Test loss: 0.27950 | Test accuracy: 89.35%\n",
      "\n",
      "Train loss: 0.25329 | Train accuracy: 89.74%\n",
      "Test loss: 0.26774 | Test accuracy: 90.17%\n",
      "\n",
      "Train loss: 0.25557 | Train accuracy: 89.39%\n",
      "Test loss: 0.26281 | Test accuracy: 90.09%\n",
      "\n",
      "Train loss: 0.26000 | Train accuracy: 89.19%\n",
      "Test loss: 0.26906 | Test accuracy: 89.87%\n",
      "\n",
      "Train loss: 0.25769 | Train accuracy: 89.32%\n",
      "Test loss: 0.26985 | Test accuracy: 90.09%\n",
      "\n",
      "Train loss: 0.26069 | Train accuracy: 89.07%\n",
      "Test loss: 0.27434 | Test accuracy: 89.71%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 100):\n",
    "    train(train_loader)\n",
    "    test(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model and evaluate âœ…\n",
    "\n",
    "We did it!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
