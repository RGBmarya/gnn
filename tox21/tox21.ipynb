{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Okay. Alright. That's fine.*\n",
    "\n",
    "\\- Drake\n",
    "\n",
    "\n",
    "\n",
    "Hyperparameter optimization did not as expected, but we have more exciting things ahead of us: creating our own graph classifier. Let's approach this task using PyTorch Geometric using this [example](https://colab.research.google.com/drive/1I8a0DfQ3fI7Njc62__mVXUlcAleUclnb?usp=sharing#scrollTo=mHSP6-RBOqCE) as reference.\n",
    "\n",
    "We can break this down into a few steps:\n",
    "- Convert SMILES data into graph data\n",
    "- Mini-batch graph data\n",
    "- Define Graph Neural Network for graph classification\n",
    "- Train model and evaluate - you know the drill \n",
    "\n",
    "Let's get to it ðŸ¤–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deepchem in ./env/lib/python3.10/site-packages (2.7.1)\n",
      "Requirement already satisfied: joblib in ./env/lib/python3.10/site-packages (from deepchem) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.21 in ./env/lib/python3.10/site-packages (from deepchem) (1.24.4)\n",
      "Requirement already satisfied: pandas in ./env/lib/python3.10/site-packages (from deepchem) (2.1.3)\n",
      "Requirement already satisfied: scikit-learn in ./env/lib/python3.10/site-packages (from deepchem) (1.3.2)\n",
      "Requirement already satisfied: scipy<1.9 in ./env/lib/python3.10/site-packages (from deepchem) (1.8.1)\n",
      "Requirement already satisfied: rdkit in ./env/lib/python3.10/site-packages (from deepchem) (2023.9.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./env/lib/python3.10/site-packages (from pandas->deepchem) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./env/lib/python3.10/site-packages (from pandas->deepchem) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./env/lib/python3.10/site-packages (from pandas->deepchem) (2023.3)\n",
      "Requirement already satisfied: Pillow in ./env/lib/python3.10/site-packages (from rdkit->deepchem) (10.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./env/lib/python3.10/site-packages (from scikit-learn->deepchem) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in ./env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->deepchem) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: deepchem[torch] in ./env/lib/python3.10/site-packages (2.7.1)\n",
      "Requirement already satisfied: joblib in ./env/lib/python3.10/site-packages (from deepchem[torch]) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.21 in ./env/lib/python3.10/site-packages (from deepchem[torch]) (1.24.4)\n",
      "Requirement already satisfied: pandas in ./env/lib/python3.10/site-packages (from deepchem[torch]) (2.1.3)\n",
      "Requirement already satisfied: scikit-learn in ./env/lib/python3.10/site-packages (from deepchem[torch]) (1.3.2)\n",
      "Requirement already satisfied: scipy<1.9 in ./env/lib/python3.10/site-packages (from deepchem[torch]) (1.8.1)\n",
      "Requirement already satisfied: rdkit in ./env/lib/python3.10/site-packages (from deepchem[torch]) (2023.9.1)\n",
      "Requirement already satisfied: torch in ./env/lib/python3.10/site-packages (from deepchem[torch]) (2.1.0)\n",
      "Requirement already satisfied: torchvision in ./env/lib/python3.10/site-packages (from deepchem[torch]) (0.16.0)\n",
      "Requirement already satisfied: pytorch-lightning in ./env/lib/python3.10/site-packages (from deepchem[torch]) (2.1.1)\n",
      "Requirement already satisfied: dgl in ./env/lib/python3.10/site-packages (from deepchem[torch]) (1.1.2.post1)\n",
      "Requirement already satisfied: dgllife in ./env/lib/python3.10/site-packages (from deepchem[torch]) (0.3.2)\n",
      "Requirement already satisfied: networkx>=2.1 in ./env/lib/python3.10/site-packages (from dgl->deepchem[torch]) (3.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./env/lib/python3.10/site-packages (from dgl->deepchem[torch]) (2.31.0)\n",
      "Requirement already satisfied: tqdm in ./env/lib/python3.10/site-packages (from dgl->deepchem[torch]) (4.66.1)\n",
      "Requirement already satisfied: psutil>=5.8.0 in ./env/lib/python3.10/site-packages (from dgl->deepchem[torch]) (5.9.6)\n",
      "Requirement already satisfied: hyperopt in ./env/lib/python3.10/site-packages (from dgllife->deepchem[torch]) (0.2.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./env/lib/python3.10/site-packages (from scikit-learn->deepchem[torch]) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./env/lib/python3.10/site-packages (from pandas->deepchem[torch]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./env/lib/python3.10/site-packages (from pandas->deepchem[torch]) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./env/lib/python3.10/site-packages (from pandas->deepchem[torch]) (2023.3)\n",
      "Requirement already satisfied: PyYAML>=5.4 in ./env/lib/python3.10/site-packages (from pytorch-lightning->deepchem[torch]) (6.0.1)\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in ./env/lib/python3.10/site-packages (from pytorch-lightning->deepchem[torch]) (2023.10.0)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in ./env/lib/python3.10/site-packages (from pytorch-lightning->deepchem[torch]) (1.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./env/lib/python3.10/site-packages (from pytorch-lightning->deepchem[torch]) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in ./env/lib/python3.10/site-packages (from pytorch-lightning->deepchem[torch]) (4.8.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in ./env/lib/python3.10/site-packages (from pytorch-lightning->deepchem[torch]) (0.9.0)\n",
      "Requirement already satisfied: filelock in ./env/lib/python3.10/site-packages (from torch->deepchem[torch]) (3.13.1)\n",
      "Requirement already satisfied: sympy in ./env/lib/python3.10/site-packages (from torch->deepchem[torch]) (1.12)\n",
      "Requirement already satisfied: jinja2 in ./env/lib/python3.10/site-packages (from torch->deepchem[torch]) (3.1.2)\n",
      "Requirement already satisfied: Pillow in ./env/lib/python3.10/site-packages (from rdkit->deepchem[torch]) (10.1.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./env/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning->deepchem[torch]) (3.9.0rc0)\n",
      "Requirement already satisfied: six>=1.5 in ./env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->deepchem[torch]) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.10/site-packages (from requests>=2.19.0->dgl->deepchem[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.10/site-packages (from requests>=2.19.0->dgl->deepchem[torch]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.10/site-packages (from requests>=2.19.0->dgl->deepchem[torch]) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.10/site-packages (from requests>=2.19.0->dgl->deepchem[torch]) (2023.7.22)\n",
      "Requirement already satisfied: future in ./env/lib/python3.10/site-packages (from hyperopt->dgllife->deepchem[torch]) (0.18.3)\n",
      "Requirement already satisfied: cloudpickle in ./env/lib/python3.10/site-packages (from hyperopt->dgllife->deepchem[torch]) (3.0.0)\n",
      "Requirement already satisfied: py4j in ./env/lib/python3.10/site-packages (from hyperopt->dgllife->deepchem[torch]) (0.10.9.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./env/lib/python3.10/site-packages (from jinja2->torch->deepchem[torch]) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./env/lib/python3.10/site-packages (from sympy->torch->deepchem[torch]) (1.3.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->deepchem[torch]) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->deepchem[torch]) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->deepchem[torch]) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->deepchem[torch]) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->deepchem[torch]) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->deepchem[torch]) (4.0.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: rdkit in ./env/lib/python3.10/site-packages (2023.9.1)\n",
      "Requirement already satisfied: numpy in ./env/lib/python3.10/site-packages (from rdkit) (1.24.4)\n",
      "Requirement already satisfied: Pillow in ./env/lib/python3.10/site-packages (from rdkit) (10.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: torch_geometric in ./env/lib/python3.10/site-packages (2.4.0)\n",
      "Requirement already satisfied: tqdm in ./env/lib/python3.10/site-packages (from torch_geometric) (4.66.1)\n",
      "Requirement already satisfied: numpy in ./env/lib/python3.10/site-packages (from torch_geometric) (1.24.4)\n",
      "Requirement already satisfied: scipy in ./env/lib/python3.10/site-packages (from torch_geometric) (1.8.1)\n",
      "Requirement already satisfied: jinja2 in ./env/lib/python3.10/site-packages (from torch_geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in ./env/lib/python3.10/site-packages (from torch_geometric) (2.31.0)\n",
      "Requirement already satisfied: pyparsing in ./env/lib/python3.10/site-packages (from torch_geometric) (3.1.1)\n",
      "Requirement already satisfied: scikit-learn in ./env/lib/python3.10/site-packages (from torch_geometric) (1.3.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in ./env/lib/python3.10/site-packages (from torch_geometric) (5.9.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./env/lib/python3.10/site-packages (from jinja2->torch_geometric) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.10/site-packages (from requests->torch_geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.10/site-packages (from requests->torch_geometric) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.10/site-packages (from requests->torch_geometric) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.10/site-packages (from requests->torch_geometric) (2023.7.22)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./env/lib/python3.10/site-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./env/lib/python3.10/site-packages (from scikit-learn->torch_geometric) (3.2.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install deepchem\n",
    "!pip install 'deepchem[torch]'\n",
    "!pip install rdkit\n",
    "!pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/mihirarya/Dev/bcil/tox21/env/lib/python3.10/site-packages/tensorflow/python/util/deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_relax_shapes is deprecated, use reduce_retracing instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n",
      "[09:58:20] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:58:34] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "import deepchem as dc\n",
    "\n",
    "tasks, datasets, transformers = dc.molnet.load_tox21(featurizer='GraphConv', reload=False)\n",
    "train_dataset, valid_dataset, test_dataset = datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a close look at this dataset by inspecting the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6264,)\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there are **6264** graphs (molecules) in our training dataset, where *X* stores the molecules as ConvMol objects, *y* stores the hot-encoded output vector with one entry for each of the **12** measures/tasks, and a weights matrix *w*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's one particular molecule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This molecule has 11 atoms with 75 features each.\n"
     ]
    }
   ],
   "source": [
    "test_mol = train_dataset.X[0]\n",
    "print(f\"This molecule has {test_mol.n_atoms} atoms with {test_mol.n_feat} features each.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6264, 783, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(valid_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note above sizes of our training, validation, and test datasets. However, we can't just operate on the above data directly as molecular information is stored as a [SMILES](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) string (that is, simplified molecular-input line-entry system). Try saying that five times fast. In short, the specification enables structural information of molecules to be encoded into a string.\n",
    "\n",
    "For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CC(O)(P(=O)(O)O)P(=O)(O)O'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.ids[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, open-source is once again our savior: [SciPy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.spmatrix.html) supplies a few helper functions to convert sparse adjacency matrices  into graph data that we *can* use with PyTorch Geometric. From there, we can extract additional metadata to help understand the numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "import numpy as np\n",
    "def adjacency_list_to_sparse(adj_list):\n",
    "    num_nodes = len(adj_list)\n",
    "    rows, cols = [], []\n",
    "\n",
    "    for i, neighbors in enumerate(adj_list):\n",
    "        rows.extend([i] * len(neighbors))\n",
    "        cols.extend(neighbors)\n",
    "\n",
    "    adjacency_matrix = scipy.sparse.coo_matrix((np.ones_like(rows), (rows, cols)),\n",
    "                                              shape=(num_nodes, num_nodes),\n",
    "                                              dtype=np.float32)\n",
    "\n",
    "    return adjacency_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from torch_geometric.utils.convert import from_scipy_sparse_matrix\n",
    "\n",
    "\n",
    "def to_data(mol_graph):\n",
    "\n",
    "    x = mol_graph.get_atom_features()\n",
    "\n",
    "    adj_list = mol_graph.get_adjacency_list()\n",
    "    sparse_mat = adjacency_list_to_sparse(adj_list)\n",
    "    edge_index, edge_attr = from_scipy_sparse_matrix(sparse_mat)\n",
    "    \n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little clarification on the `Data` object might help:\n",
    "\n",
    "1. **x (Node Feature Matrix):**\n",
    "   - This parameter represents the feature matrix for each node in the graph.\n",
    "   - It is a PyTorch tensor with shape [num_nodes, num_node_features].\n",
    "   - Each row corresponds to a node, and each column corresponds to a feature of that node.\n",
    "   - For example, if you are representing atoms in a molecule, `x` could contain features like atomic number, charge, etc.\n",
    "\n",
    "\n",
    "2. **edge_index (Graph Connectivity):**\n",
    "   - `edge_index` represents the graph connectivity in COO (Coordinate List) format.\n",
    "   - It is a PyTorch tensor with shape [2, num_edges].\n",
    "   - Each column of `edge_index` contains the indices of two nodes that form an edge.\n",
    "   - For an undirected graph, (i, j) and (j, i) should both be present in the `edge_index`.\n",
    "\n",
    "\n",
    "3. **edge_attr (Edge Feature Matrix):**\n",
    "   - `edge_attr` represents the feature matrix for each edge in the graph.\n",
    "   - It is a PyTorch tensor with shape [num_edges, num_edge_features].\n",
    "   - Each row corresponds to an edge, and each column corresponds to a feature of that edge.\n",
    "   - This is often used to store information like bond types, distances, or any other edge-specific features.\n",
    "\n",
    "While there are a few other parameters, these three collectively provide a comprehensive representation of the graph needed for our specific use case.\n",
    "\n",
    "Let's convert all our datasets from ConvMol to Data objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_graph = []\n",
    "for mol_graph in train_dataset.X:\n",
    "    data = to_data(mol_graph)\n",
    "    train_dataset_graph.append(data)\n",
    "\n",
    "valid_dataset_graph = []\n",
    "for mol_graph in valid_dataset.X:\n",
    "    data = to_data(mol_graph)\n",
    "    valid_dataset_graph.append(data)\n",
    "\n",
    "test_dataset_graph = []\n",
    "for mol_graph in test_dataset.X:\n",
    "    data = to_data(mol_graph)\n",
    "    test_dataset_graph.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[11, 75], edge_index=[2, 20], edge_attr=[20])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_graph[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "train_loader = DataLoader(train_dataset_graph, batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset_graph, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2208], edge_attr=[2208], batch=[1078], ptr=[65])\n",
      "\n",
      "Step 2:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 1876], edge_attr=[1876], batch=[948], ptr=[65])\n",
      "\n",
      "Step 3:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2260], edge_attr=[2260], batch=[1109], ptr=[65])\n",
      "\n",
      "Step 4:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2404], edge_attr=[2404], batch=[1166], ptr=[65])\n",
      "\n",
      "Step 5:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[64], edge_index=[2, 2122], edge_attr=[2122], batch=[1052], ptr=[65])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "for step, data in enumerate(itertools.islice(train_loader, 5)):\n",
    "    print(f'Step {step + 1}:')\n",
    "    print('=======')\n",
    "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "    print(data)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm. Slight issue with the x parameter, but no clear solution is popping out to me at the moment. As my friend Dan likes to say, \"Let's circle back to this.\"\n",
    "\n",
    "Also, small (*very* consequential) update: after spending 2 days trying to get perfectly preprocess this data, I have discovered that PyTorch Geometric supplies its own MoleculeNet class, complete with a Tox 21 dataset ðŸ¥².\n",
    "\n",
    "Despite how much my RAM has suffered due to tabs upon tabs of documentation, I'd say that this process helped clarify **how** and **why** we preprocess our data. Now let's condense yesterday's work into three lines!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihirarya/Dev/bcil/tox21/env/lib/python3.10/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[145459, 9], edge_index=[2, 302190], edge_attr=[302190, 3], smiles=[7831], y=[7831, 12])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.datasets import MoleculeNet\n",
    "dataset = MoleculeNet(root=\"./data/\", name=\"Tox21\")\n",
    "dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: Tox21(7831):\n",
      "====================\n",
      "Number of graphs: 7831\n",
      "Number of features: 9\n",
      "Number of classes: 12\n",
      "\n",
      "Data(x=[16, 9], edge_index=[2, 34], edge_attr=[34, 3], smiles='CCOc1ccc2nc(S(N)(=O)=O)sc2c1', y=[1, 12])\n",
      "=============================================================\n",
      "Number of nodes: 16\n",
      "Number of edges: 34\n",
      "Average node degree: 2.12\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print('=============================================================')\n",
    "\n",
    "# Gather some statistics about the first graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 12 targets to predict, which is 11 too many to do at once - let's select NR-AhR (column 3) as the target to predict. Some of the rows in our dataset have a `NaN` value for this task, so we must them filter out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1., nan, nan, 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some datatype manipulation so we don't run into issues downstream!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.y = dataset.y.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shuffle()\n",
    "column_index_to_check = 2\n",
    "filtered_data_list = [data for data in dataset if not torch.isnan(data.y[0, column_index_to_check]).any()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***KEEP AN EYE ON THIS METRIC - a crucial bit of foreshadowing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0s: 5781\n",
      "Number of 1s:  768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihirarya/Dev/bcil/tox21/env/lib/python3.10/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of 0s:\", list(dataset.data.y[:, column_index_to_check]).count(0))\n",
    "print(\"Number of 1s: \", list(dataset.data.y[:, column_index_to_check]).count(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 5239\n",
      "Number of test graphs: 1310\n"
     ]
    }
   ],
   "source": [
    "split = int(len(filtered_data_list) * 0.80)\n",
    "train_dataset, test_dataset = filtered_data_list[:split], filtered_data_list[split:]\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're cooking with this dataset: shuffled, filtered, and split. We can finally move on..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step: **Mini-batching**.\n",
    "\n",
    "Instead of \"stacking\" equally-sized matrices into a single mini-batch, as we may have done with image data, we take an alternative approach with graph data. \"Why overcomplicate things?\" you may ask. According to PyTorch Geometric [documentation](https://colab.research.google.com/drive/1I8a0DfQ3fI7Njc62__mVXUlcAleUclnb?usp=sharing#scrollTo=0gZ-l0npPIca):\n",
    "\n",
    "1. GNN operators that rely on a **message passing scheme** (more on this later) do not need to be modified since messages are not exchanged between two nodes that belong to different graphs\n",
    "\n",
    "2. There is no computational or memory overhead since adjacency matrices are saved in a sparse fashion holding only non-zero entries (*i.e.*, the edges)\n",
    "\n",
    "PyTorch Geometric automatically takes care of **batching multiple graphs into a single giant graph** with the help of the [`torch_geometric.data.DataLoader`](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.DataLoader) class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1207, 9], edge_index=[2, 2500], edge_attr=[2500, 3], smiles=[64], y=[64, 12], batch=[1207], ptr=[65])\n",
      "\n",
      "Step 2:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1370, 9], edge_index=[2, 2880], edge_attr=[2880, 3], smiles=[64], y=[64, 12], batch=[1370], ptr=[65])\n",
      "\n",
      "Step 3:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1172, 9], edge_index=[2, 2440], edge_attr=[2440, 3], smiles=[64], y=[64, 12], batch=[1172], ptr=[65])\n",
      "\n",
      "Step 4:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1073, 9], edge_index=[2, 2220], edge_attr=[2220, 3], smiles=[64], y=[64, 12], batch=[1073], ptr=[65])\n",
      "\n",
      "Step 5:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1138, 9], edge_index=[2, 2370], edge_attr=[2370, 3], smiles=[64], y=[64, 12], batch=[1138], ptr=[65])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "for step, data in enumerate(itertools.islice(train_loader, 5)):\n",
    "    print(f'Step {step + 1}:')\n",
    "    print('=======')\n",
    "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "    print(data)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mini-batch data âœ…\n",
    "\n",
    "Next step: Graph. Neural. Networks.\n",
    "\n",
    "FINALLY. Let's make like Merriam-Webster and define what our GNN is going to look like.\n",
    "\n",
    "Thank you to the wonderful people at [PyTorch](https://www.learnpytorch.io/02_pytorch_classification/) and [PyTorch Geometric](https://colab.research.google.com/drive/1I8a0DfQ3fI7Njc62__mVXUlcAleUclnb?usp=sharing#scrollTo=mHSP6-RBOqCE) for these thoroughly-documented references (they low-key carried). Take a look at them if you haven't already!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN(\n",
      "  (conv1): GraphConv(9, 64)\n",
      "  (conv2): GraphConv(64, 64)\n",
      "  (conv3): GraphConv(64, 64)\n",
      "  (lin): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GraphConv\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GNN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GraphConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2 = GraphConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GraphConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, 1) # Output a binary value (0 or 1) because this is a binary classification problem \n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        x = x.to(self.lin.weight.dtype)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = GNN(hidden_channels=64)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Graph Neural Network for graph classification âœ…\n",
    "\n",
    "\n",
    "And finally, the code that we'll use to train and test our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal\n",
    "    acc = (correct / len(y_pred)) * 100 \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "def train(loader):\n",
    "    model.train()\n",
    "\n",
    "    train_loss, train_acc = 0, 0\n",
    "    for data in loader:  # Iterate in batches over the training dataset.\n",
    "         \n",
    "         # 1. Forward pass (model outputs raw logits)\n",
    "         y_logits = model(data.x.to(torch.float32), data.edge_index, data.batch)\n",
    "         y_preds = torch.round(torch.sigmoid(y_logits))\n",
    "         y_train = data.y[:, column_index_to_check] # extract target column\n",
    "         \n",
    "         # 2. Calculate loss/accuracy\n",
    "         loss = loss_fn(y_logits.squeeze(), y_train)\n",
    "         train_loss += loss\n",
    "         train_acc += accuracy_fn(y_true=y_train, y_pred=y_preds.squeeze())\n",
    "\n",
    "         # 3. Optimizer zero grad\n",
    "         optimizer.zero_grad() \n",
    "\n",
    "         # 4. Loss backwards\n",
    "         loss.backward()  \n",
    "\n",
    "         # 5. Optimizer step\n",
    "         optimizer.step()\n",
    "    train_loss /= len(loader)\n",
    "    train_acc /= len(loader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "def test(loader):\n",
    "     model.eval()\n",
    "\n",
    "     test_loss, test_acc = 0, 0\n",
    "     for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "         test_logits = model(data.x.to(torch.float32), data.edge_index, data.batch)\n",
    "         test_preds = torch.round(torch.sigmoid(test_logits))\n",
    "         labels = data.y[:, column_index_to_check] # extract target column\n",
    "\n",
    "         test_loss += loss_fn(test_logits.squeeze(), labels)\n",
    "         test_acc += accuracy_fn(y_true=labels, y_pred=test_preds.squeeze())\n",
    "     test_loss /= len(loader)\n",
    "     test_acc /= len(loader)\n",
    "     print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihirarya/Dev/bcil/tox21/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "  1%|          | 1/100 [00:00<00:58,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.46709 | Train accuracy: 86.55%\n",
      "Test loss: 0.30009 | Test accuracy: 88.61%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 2/100 [00:01<00:50,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.32101 | Train accuracy: 88.04%\n",
      "Test loss: 0.29506 | Test accuracy: 88.61%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 3/100 [00:01<00:50,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.30924 | Train accuracy: 88.25%\n",
      "Test loss: 0.31156 | Test accuracy: 88.61%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–         | 4/100 [00:02<00:49,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.30842 | Train accuracy: 88.24%\n",
      "Test loss: 0.29471 | Test accuracy: 88.61%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 5/100 [00:02<00:49,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.30941 | Train accuracy: 88.25%\n",
      "Test loss: 0.29283 | Test accuracy: 88.61%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–Œ         | 6/100 [00:03<00:47,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.30037 | Train accuracy: 88.25%\n",
      "Test loss: 0.28817 | Test accuracy: 88.61%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 7/100 [00:03<00:47,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.30182 | Train accuracy: 88.24%\n",
      "Test loss: 0.29172 | Test accuracy: 88.61%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 8/100 [00:04<00:46,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.30725 | Train accuracy: 88.24%\n",
      "Test loss: 0.28652 | Test accuracy: 88.61%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|â–‰         | 9/100 [00:04<00:49,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.29302 | Train accuracy: 88.34%\n",
      "Test loss: 0.28141 | Test accuracy: 89.28%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 10/100 [00:05<00:48,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.29313 | Train accuracy: 88.46%\n",
      "Test loss: 0.28418 | Test accuracy: 89.26%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆ         | 11/100 [00:05<00:50,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.29138 | Train accuracy: 88.13%\n",
      "Test loss: 0.28410 | Test accuracy: 88.61%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|â–ˆâ–        | 12/100 [00:06<00:46,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.29365 | Train accuracy: 88.14%\n",
      "Test loss: 0.27985 | Test accuracy: 89.57%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|â–ˆâ–Ž        | 13/100 [00:06<00:45,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.28542 | Train accuracy: 88.39%\n",
      "Test loss: 0.29385 | Test accuracy: 88.61%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|â–ˆâ–        | 14/100 [00:07<00:44,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.28814 | Train accuracy: 88.47%\n",
      "Test loss: 0.28579 | Test accuracy: 88.75%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–Œ        | 15/100 [00:08<00:48,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.29431 | Train accuracy: 88.16%\n",
      "Test loss: 0.28014 | Test accuracy: 88.61%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|â–ˆâ–Œ        | 16/100 [00:08<00:45,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.29337 | Train accuracy: 88.31%\n",
      "Test loss: 0.28316 | Test accuracy: 88.90%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|â–ˆâ–‹        | 17/100 [00:08<00:42,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.28476 | Train accuracy: 88.33%\n",
      "Test loss: 0.27442 | Test accuracy: 88.90%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|â–ˆâ–Š        | 18/100 [00:09<00:42,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.28628 | Train accuracy: 88.66%\n",
      "Test loss: 0.27424 | Test accuracy: 88.90%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|â–ˆâ–‰        | 19/100 [00:09<00:40,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.28955 | Train accuracy: 88.57%\n",
      "Test loss: 0.26551 | Test accuracy: 89.20%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 20/100 [00:10<00:37,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.28256 | Train accuracy: 88.53%\n",
      "Test loss: 0.27328 | Test accuracy: 89.20%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|â–ˆâ–ˆ        | 21/100 [00:10<00:35,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.28081 | Train accuracy: 88.73%\n",
      "Test loss: 0.28542 | Test accuracy: 88.83%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|â–ˆâ–ˆâ–       | 22/100 [00:11<00:37,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.28357 | Train accuracy: 88.18%\n",
      "Test loss: 0.27393 | Test accuracy: 88.61%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|â–ˆâ–ˆâ–Ž       | 23/100 [00:11<00:37,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.28436 | Train accuracy: 88.53%\n",
      "Test loss: 0.27294 | Test accuracy: 89.57%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|â–ˆâ–ˆâ–       | 24/100 [00:12<00:35,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.28507 | Train accuracy: 88.78%\n",
      "Test loss: 0.31944 | Test accuracy: 88.34%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|â–ˆâ–ˆâ–Œ       | 25/100 [00:12<00:33,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.29816 | Train accuracy: 88.32%\n",
      "Test loss: 0.30190 | Test accuracy: 88.61%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|â–ˆâ–ˆâ–Œ       | 26/100 [00:13<00:33,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.27892 | Train accuracy: 88.55%\n",
      "Test loss: 0.29413 | Test accuracy: 89.80%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|â–ˆâ–ˆâ–‹       | 27/100 [00:13<00:34,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.27929 | Train accuracy: 88.69%\n",
      "Test loss: 0.26694 | Test accuracy: 89.57%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|â–ˆâ–ˆâ–Š       | 28/100 [00:14<00:34,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.27746 | Train accuracy: 88.82%\n",
      "Test loss: 0.27373 | Test accuracy: 90.23%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|â–ˆâ–ˆâ–‰       | 29/100 [00:14<00:34,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.28101 | Train accuracy: 88.38%\n",
      "Test loss: 0.26796 | Test accuracy: 89.87%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [00:15<00:33,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.27827 | Train accuracy: 88.87%\n",
      "Test loss: 0.26674 | Test accuracy: 89.42%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [00:15<00:32,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.28963 | Train accuracy: 88.47%\n",
      "Test loss: 0.26934 | Test accuracy: 89.80%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [00:15<00:31,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.28173 | Train accuracy: 88.82%\n",
      "Test loss: 0.27876 | Test accuracy: 89.33%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [00:16<00:29,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.27777 | Train accuracy: 88.84%\n",
      "Test loss: 0.25772 | Test accuracy: 89.95%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [00:16<00:29,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.27536 | Train accuracy: 88.82%\n",
      "Test loss: 0.27152 | Test accuracy: 88.83%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [00:17<00:30,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.27757 | Train accuracy: 89.02%\n",
      "Test loss: 0.26418 | Test accuracy: 90.17%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [00:17<00:33,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.27145 | Train accuracy: 89.04%\n",
      "Test loss: 0.27573 | Test accuracy: 89.20%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [00:18<00:34,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.28028 | Train accuracy: 88.79%\n",
      "Test loss: 0.27125 | Test accuracy: 89.50%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [00:18<00:31,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.27065 | Train accuracy: 88.79%\n",
      "Test loss: 0.27789 | Test accuracy: 90.09%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [00:19<00:29,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.27477 | Train accuracy: 88.95%\n",
      "Test loss: 0.26854 | Test accuracy: 90.39%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [00:19<00:28,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.27238 | Train accuracy: 89.12%\n",
      "Test loss: 0.29529 | Test accuracy: 88.88%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [00:20<00:27,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.27191 | Train accuracy: 88.92%\n",
      "Test loss: 0.26758 | Test accuracy: 90.24%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [00:20<00:27,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.27508 | Train accuracy: 88.95%\n",
      "Test loss: 0.27113 | Test accuracy: 90.39%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [00:21<00:26,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.26888 | Train accuracy: 89.24%\n",
      "Test loss: 0.26417 | Test accuracy: 90.09%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [00:21<00:25,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.26999 | Train accuracy: 88.85%\n",
      "Test loss: 0.26199 | Test accuracy: 89.65%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [00:22<00:25,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.27061 | Train accuracy: 88.68%\n",
      "Test loss: 0.27786 | Test accuracy: 90.09%\n",
      "\n",
      "Train loss: 0.27112 | Train accuracy: 88.84%\n",
      "Test loss: 0.26477 | Test accuracy: 90.54%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [00:24<00:41,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.26435 | Train accuracy: 88.91%\n",
      "Test loss: 0.26815 | Test accuracy: 89.87%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [00:25<00:39,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.27173 | Train accuracy: 88.86%\n",
      "Test loss: 0.26941 | Test accuracy: 90.24%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [00:25<00:36,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.27647 | Train accuracy: 89.29%\n",
      "Test loss: 0.26146 | Test accuracy: 89.95%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [00:26<00:32,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.26515 | Train accuracy: 89.39%\n",
      "Test loss: 0.27926 | Test accuracy: 88.90%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [00:26<00:28,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.27248 | Train accuracy: 88.88%\n",
      "Test loss: 0.27278 | Test accuracy: 89.35%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [00:27<00:26,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.26824 | Train accuracy: 89.05%\n",
      "Test loss: 0.26793 | Test accuracy: 89.05%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [00:27<00:24,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.27553 | Train accuracy: 88.65%\n",
      "Test loss: 0.26629 | Test accuracy: 89.80%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [00:27<00:22,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.27759 | Train accuracy: 88.78%\n",
      "Test loss: 0.27020 | Test accuracy: 89.65%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [00:28<00:21,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.27225 | Train accuracy: 88.86%\n",
      "Test loss: 0.26552 | Test accuracy: 89.57%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [00:29<00:23,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.27219 | Train accuracy: 88.90%\n",
      "Test loss: 0.28975 | Test accuracy: 88.68%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [00:29<00:22,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.26829 | Train accuracy: 89.26%\n",
      "Test loss: 0.26680 | Test accuracy: 89.80%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [00:30<00:22,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.27208 | Train accuracy: 88.88%\n",
      "Test loss: 0.26531 | Test accuracy: 90.02%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [00:30<00:22,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.26821 | Train accuracy: 89.02%\n",
      "Test loss: 0.27403 | Test accuracy: 88.98%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [00:31<00:20,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.26541 | Train accuracy: 89.14%\n",
      "Test loss: 0.26731 | Test accuracy: 90.02%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [00:31<00:21,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.26494 | Train accuracy: 89.05%\n",
      "Test loss: 0.26445 | Test accuracy: 90.24%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [00:32<00:20,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.26416 | Train accuracy: 89.06%\n",
      "Test loss: 0.26744 | Test accuracy: 90.02%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [00:32<00:19,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.27232 | Train accuracy: 88.68%\n",
      "Test loss: 0.28596 | Test accuracy: 88.75%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [00:33<00:19,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.27294 | Train accuracy: 89.31%\n",
      "Test loss: 0.28264 | Test accuracy: 88.68%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [00:33<00:18,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.26360 | Train accuracy: 89.33%\n",
      "Test loss: 0.26412 | Test accuracy: 90.17%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [00:34<00:17,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.26035 | Train accuracy: 89.44%\n",
      "Test loss: 0.26436 | Test accuracy: 90.24%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [00:34<00:17,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.26475 | Train accuracy: 89.21%\n",
      "Test loss: 0.27027 | Test accuracy: 89.72%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [00:35<00:16,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.25999 | Train accuracy: 89.19%\n",
      "Test loss: 0.26555 | Test accuracy: 90.17%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [00:35<00:16,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.26857 | Train accuracy: 88.86%\n",
      "Test loss: 0.26577 | Test accuracy: 89.87%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [00:36<00:15,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.26045 | Train accuracy: 89.47%\n",
      "Test loss: 0.26726 | Test accuracy: 89.65%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [00:36<00:15,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.26724 | Train accuracy: 89.11%\n",
      "Test loss: 0.30283 | Test accuracy: 89.05%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [00:37<00:14,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.26502 | Train accuracy: 89.56%\n",
      "Test loss: 0.27504 | Test accuracy: 90.09%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [00:38<00:14,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.26136 | Train accuracy: 89.22%\n",
      "Test loss: 0.25707 | Test accuracy: 89.20%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [00:38<00:13,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.25800 | Train accuracy: 89.34%\n",
      "Test loss: 0.26317 | Test accuracy: 90.24%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [00:39<00:13,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.25971 | Train accuracy: 89.40%\n",
      "Test loss: 0.26921 | Test accuracy: 89.50%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [00:39<00:12,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.26427 | Train accuracy: 89.22%\n",
      "Test loss: 0.27239 | Test accuracy: 90.39%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [00:40<00:11,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.26197 | Train accuracy: 89.50%\n",
      "Test loss: 0.26724 | Test accuracy: 89.87%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [00:40<00:10,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.26272 | Train accuracy: 89.13%\n",
      "Test loss: 0.26822 | Test accuracy: 88.98%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [00:40<00:09,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.26116 | Train accuracy: 89.23%\n",
      "Test loss: 0.26574 | Test accuracy: 89.72%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [00:41<00:09,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.25870 | Train accuracy: 89.47%\n",
      "Test loss: 0.26045 | Test accuracy: 90.09%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [00:41<00:08,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.26068 | Train accuracy: 89.41%\n",
      "Test loss: 0.26254 | Test accuracy: 89.13%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [00:42<00:08,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.25773 | Train accuracy: 89.31%\n",
      "Test loss: 0.26747 | Test accuracy: 89.87%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [00:42<00:08,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.26009 | Train accuracy: 89.31%\n",
      "Test loss: 0.26785 | Test accuracy: 89.80%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [00:43<00:07,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.25792 | Train accuracy: 89.07%\n",
      "Test loss: 0.26587 | Test accuracy: 90.09%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [00:43<00:06,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.25971 | Train accuracy: 89.19%\n",
      "Test loss: 0.28663 | Test accuracy: 90.01%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [00:44<00:06,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.26520 | Train accuracy: 89.06%\n",
      "Test loss: 0.28156 | Test accuracy: 89.28%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [00:44<00:05,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.26490 | Train accuracy: 89.29%\n",
      "Test loss: 0.25390 | Test accuracy: 90.39%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [00:45<00:05,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.26048 | Train accuracy: 89.15%\n",
      "Test loss: 0.27182 | Test accuracy: 89.80%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [00:45<00:05,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.25951 | Train accuracy: 89.41%\n",
      "Test loss: 0.25865 | Test accuracy: 90.17%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [00:46<00:04,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.25731 | Train accuracy: 89.49%\n",
      "Test loss: 0.26551 | Test accuracy: 89.95%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [00:46<00:04,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.26023 | Train accuracy: 89.07%\n",
      "Test loss: 0.27571 | Test accuracy: 89.13%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [00:47<00:03,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.25869 | Train accuracy: 89.24%\n",
      "Test loss: 0.25922 | Test accuracy: 90.24%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [00:47<00:03,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.26001 | Train accuracy: 89.14%\n",
      "Test loss: 0.26961 | Test accuracy: 89.35%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [00:47<00:02,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.25758 | Train accuracy: 89.43%\n",
      "Test loss: 0.27950 | Test accuracy: 89.35%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [00:48<00:02,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.25329 | Train accuracy: 89.74%\n",
      "Test loss: 0.26774 | Test accuracy: 90.17%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [00:48<00:01,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.25557 | Train accuracy: 89.39%\n",
      "Test loss: 0.26281 | Test accuracy: 90.09%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [00:49<00:01,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.26000 | Train accuracy: 89.19%\n",
      "Test loss: 0.26906 | Test accuracy: 89.87%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [00:49<00:01,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.25769 | Train accuracy: 89.32%\n",
      "Test loss: 0.26985 | Test accuracy: 90.09%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [00:50<00:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.26069 | Train accuracy: 89.07%\n",
      "Test loss: 0.27434 | Test accuracy: 89.71%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:51<00:00,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.25498 | Train accuracy: 89.47%\n",
      "Test loss: 0.29478 | Test accuracy: 88.89%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "epochs = 100\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train(train_loader)\n",
    "    test(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model and evaluate âœ…\n",
    "\n",
    "We did it!\n",
    "\n",
    "Let's pause here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just kidding! Job not finished ðŸ˜¤\n",
    "\n",
    "There are two key issues with the above (alongside many other things that I am probably overlooking):\n",
    "1. VERY unbalanced dataset of targets - take a look at the number of 0s vs the number of 1s. This leads to an artificially high model accuracy.\n",
    "2. Accuracy may not be the best \"accuracy\" metric here. [MoleculeNet](https://moleculenet.org/datasets-1) recommends ROC-AUC (Area Under Curve of Receiver Operating Characteristics) as a classification metric.\n",
    "\n",
    "Let's integrate these changes. Head to `mutag.ipynb`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
